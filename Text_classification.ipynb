{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUpgETXBFSyIaps2R3klGE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sejalvyas13/Basic-CYK-Parser/blob/master/Text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgwpCPpTl4-b"
      },
      "source": [
        "**Download data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RGA_AExlXc-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f94fcf92-9f83-4356-8511-3b2238e23611"
      },
      "source": [
        "!wget https://github.com/pmichel31415/mtnt/releases/download/v1.1/MTNT.1.1.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-21 15:29:00--  https://github.com/pmichel31415/mtnt/releases/download/v1.1/MTNT.1.1.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/125262764/1b3bee80-1e45-11e9-90db-a9db0f519608?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20201221%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20201221T152901Z&X-Amz-Expires=300&X-Amz-Signature=212f4c115ca5b46f948c3f33bdd53b18cf54071ed145e00b9a551c122320cb8a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=125262764&response-content-disposition=attachment%3B%20filename%3DMTNT.1.1.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-12-21 15:29:01--  https://github-production-release-asset-2e65be.s3.amazonaws.com/125262764/1b3bee80-1e45-11e9-90db-a9db0f519608?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20201221%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20201221T152901Z&X-Amz-Expires=300&X-Amz-Signature=212f4c115ca5b46f948c3f33bdd53b18cf54071ed145e00b9a551c122320cb8a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=125262764&response-content-disposition=attachment%3B%20filename%3DMTNT.1.1.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.206.219\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.206.219|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36786600 (35M) [application/octet-stream]\n",
            "Saving to: ‘MTNT.1.1.tar.gz’\n",
            "\n",
            "MTNT.1.1.tar.gz     100%[===================>]  35.08M  64.8MB/s    in 0.5s    \n",
            "\n",
            "2020-12-21 15:29:01 (64.8 MB/s) - ‘MTNT.1.1.tar.gz’ saved [36786600/36786600]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDuNO-l9mExa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8acbf33-3c9c-4d8f-89d7-f8fd9a09e29b"
      },
      "source": [
        "!tar -xvzf MTNT.1.1.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MTNT/\n",
            "MTNT/README.md\n",
            "MTNT/monolingual/\n",
            "MTNT/monolingual/dev.en\n",
            "MTNT/monolingual/dev.fr\n",
            "MTNT/monolingual/dev.ja\n",
            "MTNT/monolingual/dev.tok.en\n",
            "MTNT/monolingual/dev.tok.fr\n",
            "MTNT/monolingual/dev.tok.ja\n",
            "MTNT/monolingual/train.en\n",
            "MTNT/monolingual/train.fr\n",
            "MTNT/monolingual/train.ja\n",
            "MTNT/monolingual/train.tok.en\n",
            "MTNT/monolingual/train.tok.fr\n",
            "MTNT/monolingual/train.tok.ja\n",
            "MTNT/split_tsv.sh\n",
            "MTNT/test/\n",
            "MTNT/test/test.en-fr.tsv\n",
            "MTNT/test/test.en-ja.tsv\n",
            "MTNT/test/test.fr-en.tsv\n",
            "MTNT/test/test.ja-en.tsv\n",
            "MTNT/train/\n",
            "MTNT/train/train.en-fr.tsv\n",
            "MTNT/train/train.en-ja.tsv\n",
            "MTNT/train/train.fr-en.tsv\n",
            "MTNT/train/train.ja-en.tsv\n",
            "MTNT/valid/\n",
            "MTNT/valid/valid.en-fr.tsv\n",
            "MTNT/valid/valid.en-ja.tsv\n",
            "MTNT/valid/valid.fr-en.tsv\n",
            "MTNT/valid/valid.ja-en.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX9l6kzomIw4"
      },
      "source": [
        "!bash MTNT/split_tsv.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2_RJY5DmZvI"
      },
      "source": [
        "!mkdir iwslt17"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sh5NO_BmfoY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "009a6fa1-1360-42ac-8ed7-310da5368d34"
      },
      "source": [
        "cd iwslt17/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/iwslt17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU8-evIXDPEF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "883ebd8c-f73c-4341-9581-cae6f49ef8b0"
      },
      "source": [
        "!bash extract_data.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://wit3.fbk.eu/archive/2017-01-trnted/texts/fr/en/fr-en.tgz...\n",
            "--2020-12-21 15:33:16--  https://wit3.fbk.eu/archive/2017-01-trnted/texts/fr/en/fr-en.tgz\n",
            "Resolving wit3.fbk.eu (wit3.fbk.eu)... 74.125.129.121, 2607:f8b0:4001:c1d::79\n",
            "Connecting to wit3.fbk.eu (wit3.fbk.eu)|74.125.129.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2020-12-21 15:33:16 ERROR 404: Not Found.\n",
            "\n",
            "Data not successfully downloaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njYaPXcQGDyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9fd0c02-49ae-47a4-ab1d-0ec3734f1351"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nep9C6H_GKJa"
      },
      "source": [
        "mkdir input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZeALNjsaXmb"
      },
      "source": [
        "Install Fairseq to download test data using sacrebleu command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3MQfQ8WadY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da2e430c-cd02-4851-8b06-3ba1057d3e18"
      },
      "source": [
        "!pip install fairseq\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing collected packages: PyYAML, omegaconf, antlr4-python3-runtime, hydra-core, portalocker, sacrebleu, dataclasses, fairseq\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.4.1 antlr4-python3-runtime-4.8 dataclasses-0.6 fairseq-0.10.2 hydra-core-1.0.6 omegaconf-2.0.6 portalocker-2.0.0 sacrebleu-1.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtwOaUIPag4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34913c7d-dc0f-4b9f-bb90-3815711bbaa7"
      },
      "source": [
        "!git clone https://github.com/pytorch/fairseq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 71, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 22049 (delta 14), reused 35 (delta 9), pack-reused 21978\u001b[K\n",
            "Receiving objects: 100% (22049/22049), 10.21 MiB | 23.76 MiB/s, done.\n",
            "Resolving deltas: 100% (16435/16435), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tcxVUhlawmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "097decc7-19a9-46a9-8194-10fb7cf556dc"
      },
      "source": [
        "cd fairseq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fairseq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZl8C-Waaldq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd2a7e71-16b5-4aa4-9c38-74fb955ec13e"
      },
      "source": [
        "!pip install --editable ./"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+aa5f011) (2019.12.20)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+aa5f011) (1.14.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+aa5f011) (0.29.22)\n",
            "Requirement already satisfied: omegaconf<2.1 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+aa5f011) (2.0.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+aa5f011) (1.8.1+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+aa5f011) (4.41.1)\n",
            "Requirement already satisfied: numpy; python_version >= \"3.7\" in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+aa5f011) (1.19.5)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+aa5f011) (1.5.1)\n",
            "Requirement already satisfied: hydra-core<1.1 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+aa5f011) (1.0.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==1.0.0a0+aa5f011) (2.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+aa5f011) (3.7.4.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+aa5f011) (5.4.1)\n",
            "Requirement already satisfied: portalocker==2.0.0 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+aa5f011) (2.0.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1->fairseq==1.0.0a0+aa5f011) (5.1.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1->fairseq==1.0.0a0+aa5f011) (4.8)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core<1.1->fairseq==1.0.0a0+aa5f011) (3.4.1)\n",
            "Installing collected packages: fairseq\n",
            "  Found existing installation: fairseq 0.10.2\n",
            "    Uninstalling fairseq-0.10.2:\n",
            "      Successfully uninstalled fairseq-0.10.2\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed fairseq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwN7QTGZaySm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0542c786-14ce-47be-aa8b-46ecdb5195ac"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xhd1ZGcLZMli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32835e65-84f2-42db-903c-57b249c752ff"
      },
      "source": [
        "cd iwslt17"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'iwslt17'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXN1bCWzaIF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0d929cd-58f6-4193-d995-fc173f09a05b"
      },
      "source": [
        "!sacrebleu --test-set iwslt17 --language-pair en-fr --echo src > test.en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sacreBLEU: Downloading https://wit3.fbk.eu/archive/2017-01-ted-test/texts/en/fr/en-fr.tgz to /root/.sacrebleu/iwslt17/en-fr.tgz\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/sacrebleu\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sacrebleu/sacrebleu.py\", line 213, in main\n",
            "    print_test_set(test_set, args.langpair, args.echo, args.origlang, args.subset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sacrebleu/utils.py\", line 106, in print_test_set\n",
            "    files = [get_source_file(test_set, langpair)]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sacrebleu/utils.py\", line 127, in get_source_file\n",
            "    return get_files(test_set, langpair)[0]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sacrebleu/utils.py\", line 170, in get_files\n",
            "    download_test_set(test_set, langpair)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sacrebleu/utils.py\", line 199, in download_test_set\n",
            "    with urllib.request.urlopen(dataset) as f, open(tarball, 'wb') as out:\n",
            "  File \"/usr/lib/python3.6/urllib/request.py\", line 223, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "  File \"/usr/lib/python3.6/urllib/request.py\", line 532, in open\n",
            "    response = meth(req, response)\n",
            "  File \"/usr/lib/python3.6/urllib/request.py\", line 642, in http_response\n",
            "    'http', request, response, code, msg, hdrs)\n",
            "  File \"/usr/lib/python3.6/urllib/request.py\", line 570, in error\n",
            "    return self._call_chain(*args)\n",
            "  File \"/usr/lib/python3.6/urllib/request.py\", line 504, in _call_chain\n",
            "    result = func(*args)\n",
            "  File \"/usr/lib/python3.6/urllib/request.py\", line 650, in http_error_default\n",
            "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
            "urllib.error.HTTPError: HTTP Error 404: Not Found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgTUuCBWZT3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc9e28c2-0eaf-46cf-bf80-6dc1aaf318e7"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKY9Q1DEVYet"
      },
      "source": [
        "**Move IWSLT and MTNT data to input folder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBRJ4bY9GMmg"
      },
      "source": [
        "mv iwslt17/orig/fr-en/train.en input/iwlst_en.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNlH0L7qG8TL"
      },
      "source": [
        "mv MTNT/train/train.fr-en.en input/MTNT_en.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fEPuQn3c3y6"
      },
      "source": [
        "mv iwslt17/test.en input/iwslt_test.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itlD2lHrjvng"
      },
      "source": [
        "mv MTNT/test/test.en-fr.en input/mtnt_test1.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nECf_iwpkLH1"
      },
      "source": [
        "mv MTNT/test/test.fr-en.en input/mtnt_test2.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX5cz862laWh"
      },
      "source": [
        "cat input/mtnt_test1.txt input/mtnt_test2.txt > input/mtnt_test.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W91L4v2MiQ2U",
        "outputId": "d6e98259-ddce-4ca5-b42f-8a624fe36f88"
      },
      "source": [
        "cd content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5Iw3nlzVlbb"
      },
      "source": [
        "**Create a Dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Yww3URcHVt9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f9a51f-bb19-4116-e8d7-f660b274306a"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "filepath_dict = {1: 'input/iwlst_en.txt',\n",
        "                 2: 'input/MTNT_en.txt'}\n",
        "\n",
        "df_list = []\n",
        "for source, filepath in filepath_dict.items():\n",
        "    df = pd.read_csv(filepath, names=['sentence'], sep='\\n')\n",
        "    df['source'] = source\n",
        "    df_list.append(df)\n",
        "\n",
        "df = pd.concat(df_list)\n",
        "print(df.iloc[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence    al gore : averting the climate crisis\n",
            "source                                          1\n",
            "Name: 0, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHN4BRsAcp_l"
      },
      "source": [
        "Test data IWSLT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYhjHXgbcr6G"
      },
      "source": [
        "filepath_dict1 = {1: 'input/iwslt_test.txt'}\n",
        "df_list1 = []\n",
        "for source, filepath in filepath_dict1.items():\n",
        "    df1 = pd.read_csv(filepath, names=['sentence'], sep='\\n')\n",
        "    df1['source'] = source\n",
        "    df_list1.append(df1)\n",
        "\n",
        "df1 = pd.concat(df_list1)\n",
        "\n",
        "iwslt_test_sentences = df1['sentence'].values\n",
        "iwslt_y = df1['source'].values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGxevWq5lBJZ"
      },
      "source": [
        "Test data MTNT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QroletgRdSHl"
      },
      "source": [
        "filepath_dict2 = {2: 'input/mtnt_test.txt'}\n",
        "df_list2 = []\n",
        "for source, filepath in filepath_dict2.items():\n",
        "    df2 = pd.read_csv(filepath, names=['sentence'], sep='\\n')\n",
        "    df2['source'] = source\n",
        "    df_list2.append(df2)\n",
        "\n",
        "df2 = pd.concat(df_list2)\n",
        "\n",
        "mtnt_test_sentences = df2['sentence'].values\n",
        "mtnt_y = df2['source'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJmZ4FrtcKdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "716f935e-cff1-44f8-f757-b37ea482414b"
      },
      "source": [
        "#check if dataframe has proper data\n",
        "print(len(df))\n",
        "print(df.iloc[2532])\n",
        "print(df.iloc[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "245736\n",
            "sentence    mustard exists , just like tomato sauce , on a...\n",
            "source                                                      1\n",
            "Name: 2532, dtype: object\n",
            "sentence    al gore : averting the climate crisis\n",
            "source                                          1\n",
            "Name: 0, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_qVdYbvVvrV"
      },
      "source": [
        "**For now, split the train into train and test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9W1hjfP2qjQ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sentences = df['sentence'].values\n",
        "y = df['source'].values\n",
        "\n",
        "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.25, random_state=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plHfH3zkV0oA"
      },
      "source": [
        "**CountVectorizer uses skip-gram model for embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ailKECCw27IU"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(sentences_train)\n",
        "\n",
        "X_train = vectorizer.transform(sentences_train)\n",
        "X_test  = vectorizer.transform(sentences_test)\n",
        "iwslt_test = vectorizer.transform(iwslt_test_sentences)\n",
        "mtnt_test = vectorizer.transform(mtnt_test_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6skf1FJV8rW"
      },
      "source": [
        "**Basic Logistic regression for classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kCVxxC33DNX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "037234bd-1ee2-4d29-f286-0100168729c5"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, y_train)\n",
        "score = classifier.score(X_test, y_test)\n",
        "print(\"Accuracy:\", score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9650519256437803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PqHM_-3d3B-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21042e15-ac01-428c-e555-709c7e99d5de"
      },
      "source": [
        "iwslt_score = classifier.score(iwslt_test, iwslt_y)\n",
        "print(\"Accuracy on IWSLT test data:\", score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on IWSLT test data: 0.9650519256437803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7Hjo-4il0OQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77cda65a-2ce1-4472-ea80-56125d957164"
      },
      "source": [
        "mtnt_score = classifier.score(mtnt_test, mtnt_y)\n",
        "print(\"Accuracy on IWSLT test data:\", score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on IWSLT test data: 0.9650519256437803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A44fYlwE38WC"
      },
      "source": [
        "**Neural networks**\n",
        "\n",
        "Simple NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyY8ZcEV3umm"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "input_dim = X_train.shape[1]  # Number of features\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8YDtq5E4Hwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc92e4e-0bbc-4398-987f-62fe8a36a684"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "               optimizer='adam',\n",
        "               metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10)                566670    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 566,681\n",
            "Trainable params: 566,681\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd6zu08q4p-y"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                   epochs=20,\n",
        "                     verbose=False,\n",
        "                     validation_data=(X_test, y_test),\n",
        "                     batch_size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBWvplA14y2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a9036c2-5c5d-4dc4-99c5-f02a5953820a"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(iwslt_test, iwslt_y, verbose=False)\n",
        "print(\"IWSLT Test Accuracy:  {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(mtnt_test, mtnt_y, verbose=False)\n",
        "print(\"MTNT Test Accuracy:  {:.4f}\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.9255\n",
            "Testing Accuracy:  0.9262\n",
            "IWSLT Test Accuracy:  1.0000\n",
            "MTNT Test Accuracy:  1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pymj05jKemYc"
      },
      "source": [
        "**LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiND6s8ves-4"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import SpatialDropout1D\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "MAX_NB_WORDS = 50000\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X_train.shape[1]))\n",
        "model2.add(SpatialDropout1D(0.2))\n",
        "model2.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model2.add(Dense(13, activation='softmax'))\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "epochs = 5\n",
        "batch_size = 64\n",
        "\n",
        "#history2 = model2.fit(X_train, y_train, epochs=5, batch_size=64,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yiDMQniy1oj"
      },
      "source": [
        "history2 = model2.fit(X_train.toarray(), y_train.toarray(),\n",
        "                   epochs=20,\n",
        "                     verbose=False,\n",
        "                     validation_split=0.05,\n",
        "                     batch_size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubhoiZIEfExX"
      },
      "source": [
        "accr = model2.evaluate(X_test,y_test)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N0p5wvVfIYu"
      },
      "source": [
        "accr = model2.evaluate(iwslt_test, iwslt_y)\n",
        "print('Test set IWSLT  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N99d9gYDmZL5"
      },
      "source": [
        "accr = model2.evaluate(mtnt_test, mtnt_y)\n",
        "print('Test set MTNT  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1TZBUbKIdEL"
      },
      "source": [
        "**Clustering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUt9IHxaIh3w"
      },
      "source": [
        "Merge and shuffle MTNT and IWSLT text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHOAxMdqImp9"
      },
      "source": [
        "!cat input/MTNT_en.txt input/iwlst_en.txt > input/merged.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWU6enoPIlgM"
      },
      "source": [
        "!shuf --random-source=input/merged.txt input/merged.txt > input/shuffled.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diUTN-7oI9UW"
      },
      "source": [
        "Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pUKb3OEI_CC"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gensim.models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndEDlqSSXVuz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8071be90-0c4d-412f-fdeb-d1cca3b14798"
      },
      "source": [
        "document = []\n",
        "\n",
        "for line in open('input/shuffled.txt', 'r'):\n",
        "  text = line.strip().split('>')\n",
        "  document = document + text\n",
        "\n",
        "print(document[0:5])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['President Macron receives a \"godfather of the mob.\" And the nice little fat Korean, when is he coming?', 'This picture shows that the revolution has allowed opportunities for training, for education.', 'I said, \"I\\'m going to win an award,\" because I had never won an award in my entire life.', \"Hollow organs have a much higher degree of complexity, because you're asking these organs to act on demand.\", \"He's the guy put in charge. He's the Paul Bremer or the Jerry Bremer of first Kosovo and then East Timor. He governs the places.\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTgddVNYHxz0"
      },
      "source": [
        "TODO: Use gensim to obtain word embeddings\n",
        "model = gensim.models.Word2Vec(sentences=sentences)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYdGD4pGJNe4"
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(document)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixiBqKs8dN71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e188bcf0-62d8-44e7-f7f9-9c144e2c4552"
      },
      "source": [
        "true_k = 2\n",
        "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
        "model.fit(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
              "       n_clusters=2, n_init=1, n_jobs=None, precompute_distances='auto',\n",
              "       random_state=None, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsOPlrjsuYqR"
      },
      "source": [
        "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
        "terms = vectorizer.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CvT3YKeucFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c16c29d8-e4e6-4204-a04d-4b5701c28764"
      },
      "source": [
        "for i in range(true_k):\n",
        " print(\"Cluster\", i)\n",
        " for ind in order_centroids[i, :10]:\n",
        "  print(terms[ind])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cluster 0\n",
            "like\n",
            "just\n",
            "know\n",
            "thank\n",
            "think\n",
            "really\n",
            "don\n",
            "ve\n",
            "time\n",
            "want\n",
            "Cluster 1\n",
            "people\n",
            "going\n",
            "know\n",
            "think\n",
            "like\n",
            "just\n",
            "don\n",
            "really\n",
            "world\n",
            "say\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrAdlLdHu72G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a12942ae-79ac-473a-dd15-b238e94c531f"
      },
      "source": [
        "print(\"\\n\")\n",
        "print(\"Prediction\")\n",
        "X = vectorizer.transform([\"| 2016 Slate makes his anti-Christian propaganda.\"])\n",
        "predicted = model.predict(X)\n",
        "print(predicted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Prediction\n",
            "[0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQpxtF6bwFOD"
      },
      "source": [
        "X_mtnt = []\n",
        "X_iwslt = []\n",
        "\n",
        "for line in open('input/MTNT_en.txt', 'r'):\n",
        "  text = line.strip().split('>')\n",
        "  X_mtnt = X_mtnt + text\n",
        "\n",
        "for line in open('input/iwlst_en.txt', 'r'):\n",
        "  text = line.strip().split('>')\n",
        "  X_iwslt = X_iwslt + text\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUqYokAcxIQs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79e34c55-3509-44c6-c90f-4257f1d1d66a"
      },
      "source": [
        "print(\"\\n\")\n",
        "print(\"Prediction\")\n",
        "X1 = vectorizer.transform(X_mtnt)\n",
        "predicted1 = model.predict(X1)\n",
        "print(predicted1)\n",
        "\n",
        "X2 = vectorizer.transform(X_iwslt)\n",
        "predicted2 = model.predict(X2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Prediction\n",
            "[0 0 0 ... 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0vBkEBwz537",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8712b30d-d1ba-4098-babe-76807b467c7e"
      },
      "source": [
        "print(len(predicted1))\n",
        "print(type(predicted1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21206\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwSvUHbIxpM0"
      },
      "source": [
        "predicted = predicted1.tolist() + predicted2.tolist()\n",
        "realVals = [0 for i in range(len(predicted2))] + [1 for i in range(len(predicted1))]\n",
        "#0 for iwslt and 1 for mtnt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsY1C0m-yRqJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "827342a1-855b-4c44-b6f3-19b48aac34f8"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "acc = accuracy_score(y_true=realVals, y_pred=predicted)\n",
        "print('Accuracy:', acc)\n",
        "#Accuracy on training data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8481023034674974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iEjT2tF1hjU"
      },
      "source": [
        "Accuracy on IWSLT test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueNWQK1o1jk6"
      },
      "source": [
        "iwslt_test = []\n",
        "for line in open('input/iwslt_test.txt', 'r'):\n",
        "  text = line.strip().split('>')\n",
        "  iwslt_test = iwslt_test + text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3GAuft21Qje"
      },
      "source": [
        "X3 = vectorizer.transform(iwslt_test)\n",
        "predicted3 = model.predict(X3)\n",
        "\n",
        "realVals_iwslt_test = [0 for i in range(len(predicted3))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TEE8lzH18_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4923f55b-a860-42e6-c193-7a31e28f7b98"
      },
      "source": [
        "acc = accuracy_score(y_true=realVals_iwslt_test, y_pred=predicted3)\n",
        "print('Accuracy on IWSLT test:', acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on IWSLT test: 0.9085910652920962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuDj3cK5VIiA"
      },
      "source": [
        "Accuracy on MTNT test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VmvrkenVJ9d"
      },
      "source": [
        "mtnt_test = []\n",
        "for line in open('input/mtnt_test.txt', 'r'):\n",
        "  text = line.strip().split('>')\n",
        "  mtnt_test = mtnt_test + text\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClPW0I4ZV9G1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96a1fc68-110c-49fb-8eb2-54446549b3f8"
      },
      "source": [
        "print(len(mtnt_test))\n",
        "print(mtnt_test[0:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2098\n",
            "['Lebron is now 22-0 versus Kemba', 'I tried drinking hot water instead of tea with honey - it does help, although it’s not as good.', 'If you do this, you’re a monster  That’s beautiful.', 'What was your \"I shouldn\\'t have said that\" moment when talking to a customer?', 'How the hell do you get a one night stand?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k5pAlvXVTFq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "f5f97330-610a-437d-9f15-99f24182f295"
      },
      "source": [
        "X4 = vectorizer.transform(mtnt_test)\n",
        "vec = vectorizer.fit(iwslt_test)\n",
        "\n",
        "list2Vec = vec.transform(mtnt_test)  # transform list2 using vec\n",
        "predicted4 = km.predict(list2Vec)\n",
        "#predicted4 = model.predict(X4)\n",
        "\n",
        "realVals_mtnt_test = [1 for i in range(len(predicted4))]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-d9fa5193aef2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtnt_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miwslt_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlist2Vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtnt_test\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# transform list2 using vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredicted4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist2Vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \"\"\"\n\u001b[1;32m   1185\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_for_unused_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1220\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \"\"\"\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: lower not found"
          ]
        }
      ]
    }
  ]
}