{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEbVBSMFW/qbzt2UUb8Gcy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sejalvyas13/Basic-CYK-Parser/blob/master/IWSLT_MTNT_word2ket_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3625ram_hwYh",
        "outputId": "24afd87e-0f90-4abd-ab5d-fc15dfc72990"
      },
      "source": [
        "!pip install word2ket\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting word2ket\n",
            "  Downloading https://files.pythonhosted.org/packages/78/09/6b115fd2d10caff1d7b25cd2e39da803eb4e954c27f62f07c39862ab13dc/word2ket-0.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from word2ket) (1.8.1+cu101)\n",
            "Collecting gpytorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/d0/96634a8ae84b08bd64709c1abd4f319a70f404967c598690bca8be143fb8/gpytorch-1.4.0.tar.gz (286kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 12.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->word2ket) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->word2ket) (3.7.4.3)\n",
            "Building wheels for collected packages: gpytorch\n",
            "  Building wheel for gpytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpytorch: filename=gpytorch-1.4.0-py2.py3-none-any.whl size=477826 sha256=15065255379b8428e5398c70b9ebc371c11b7008ad1464b0897dadd058febabd\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/f5/39/404e1875f841e8a999e94a7efa17f6ef900298be5452b63b0c\n",
            "Successfully built gpytorch\n",
            "Installing collected packages: gpytorch, word2ket\n",
            "Successfully installed gpytorch-1.4.0 word2ket-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drVKrVSuimj5",
        "outputId": "96e94281-9324-4be8-d537-3d07710be6a8"
      },
      "source": [
        "# Install Texar-PyTorch\n",
        "!pip install texar-pytorch\n",
        "# Install Rouge\n",
        "!pip install rouge"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting texar-pytorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/7e/20aa39ee9d19dcd1a1c0db4dad878088cfba216f45aeaa8fa89615ef46c0/texar_pytorch-0.1.2.post1-py3-none-any.whl (434kB)\n",
            "\r\u001b[K     |▊                               | 10kB 20.5MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20kB 21.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30kB 23.1MB/s eta 0:00:01\r\u001b[K     |███                             | 40kB 19.4MB/s eta 0:00:01\r\u001b[K     |███▊                            | 51kB 15.1MB/s eta 0:00:01\r\u001b[K     |████▌                           | 61kB 14.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 81kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 102kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 112kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 122kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 143kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 153kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 163kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 174kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 184kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 194kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 204kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 215kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 225kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 235kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 245kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 256kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 266kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 276kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 286kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 296kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 307kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 317kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 327kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 337kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 348kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 358kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 368kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 378kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 389kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 399kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 409kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 419kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 430kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 440kB 12.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex>=2018.01.10 in /usr/local/lib/python3.7/dist-packages (from texar-pytorch) (2019.12.20)\n",
            "Collecting mypy-extensions\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/eb/975c7c080f3223a5cdaff09612f3a5221e4ba534f7039db34c35d95fa6a5/mypy_extensions-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from texar-pytorch) (2.23.0)\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.7/dist-packages (from texar-pytorch) (20.9)\n",
            "Collecting funcsigs\n",
            "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy<=1.19.5,>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from texar-pytorch) (1.19.5)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/e2/813dff3d72df2f49554204e7e5f73a3dc0f0eb1e3958a4cad3ef3fb278b7/sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 31.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->texar-pytorch) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->texar-pytorch) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->texar-pytorch) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->texar-pytorch) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=19.0->texar-pytorch) (2.4.7)\n",
            "Installing collected packages: mypy-extensions, funcsigs, sentencepiece, texar-pytorch\n",
            "Successfully installed funcsigs-1.0.2 mypy-extensions-0.4.3 sentencepiece-0.1.91 texar-pytorch-0.1.2.post1\n",
            "Collecting rouge\n",
            "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpZmH0fiiyhQ",
        "outputId": "c7cc8189-9049-4a97-85b4-bc60f7860184"
      },
      "source": [
        "!git clone https://github.com/panaali/word2ket.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'word2ket'...\n",
            "remote: Enumerating objects: 90, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 90 (delta 40), reused 56 (delta 20), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (90/90), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt9LPQ3ki9dJ",
        "outputId": "6a106029-6e0d-486d-ee59-7259024a542b"
      },
      "source": [
        "cd word2ket/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/word2ket\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADUhp8iqi5Ay",
        "outputId": "2546a7f0-5dc6-480a-e138-13145ffc4546"
      },
      "source": [
        "cd ./examples/texar/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/word2ket/examples/texar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fMk3IaAi7TU",
        "outputId": "6a659fb8-3ebd-40b7-ba73-5af9f3de0e48"
      },
      "source": [
        "!python ./prepare_data.py --data iwslt14\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded iwslt14.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00S7tjbRjGc-",
        "outputId": "59c7b623-5522-4c8f-e62c-db317a2272b3"
      },
      "source": [
        "# Using EmbeddingKet Layer\n",
        "!python seq2seq_attn.py --embedding_type EmbeddingKet   --gpu 0 --runName V2K_I_000       --config-model config_model --config-data config_iwslt14 --order 4 --rank 1\n",
        "\n",
        "# Using EmbeddingKetXS Layer\n",
        "!python seq2seq_attn.py --embedding_type EmbeddingKetXS --gpu 0 --runName V2K_XS_I_000 --config-model config_model --config-data config_iwslt14 --order 4 --rank 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embedding_type EmbeddingKet order 4 embedding_dim 256 rank 1\n",
            "train_data.source_vocab.size 116400\n",
            "train_data.target_vocab.size 93928\n",
            "Module Name                                                                           Total Parameters  Trainable Parameters # Elements in Trainable Parametrs       \n",
            "EmbeddingKet(116400, 256)                                                             1                 1                    1,862,400                               \n",
            "EmbeddingKet(93928, 256)                                                              1                 1                    1,502,848                               \n",
            "LSTMCell(256, 256)                                                                    4                 4                    526,336                                 \n",
            "LSTMCell(256, 256)                                                                    4                 4                    526,336                                 \n",
            "EmbeddingKet(93928, 256)                                                              1                 1                    1,502,848                               \n",
            "LSTMCell(512, 256)                                                                    4                 4                    788,480                                 \n",
            "Linear(in_features=768, out_features=256, bias=False)                                 1                 1                    196,608                                 \n",
            "Linear(in_features=256, out_features=93928, bias=True)                                2                 2                    24,139,496                              \n",
            "Linear(in_features=512, out_features=256, bias=False)                                 1                 1                    131,072                                 \n",
            "Total number of trainable parameters elements 31,176,424\n",
            "test RUN V2K_I_000 config_model config_iwslt14\n",
            "TRAIN: step=0, loss=125.8772\n",
            "TRAIN: step=200, loss=92.3202\n",
            "TRAIN: step=400, loss=16.7815\n",
            "TRAIN: step=600, loss=263.1789\n",
            "TRAIN: step=800, loss=170.0981\n",
            "TRAIN: step=1000, loss=34.4797\n",
            "TRAIN: step=1200, loss=167.0502\n",
            "TRAIN: step=1400, loss=220.6019\n",
            "TRAIN: step=1600, loss=79.1762\n",
            "TRAIN: step=1800, loss=139.2044\n",
            "TRAIN: step=2000, loss=51.9179\n",
            "TRAIN: step=2200, loss=181.8979\n",
            "TRAIN: step=2400, loss=234.6674\n",
            "TRAIN: step=2600, loss=93.7046\n",
            "TRAIN: step=2800, loss=71.5082\n",
            "TRAIN: step=3000, loss=109.4988\n",
            "TRAIN: step=3200, loss=219.9145\n",
            "TRAIN: step=3400, loss=77.5318\n",
            "TRAIN: step=3600, loss=48.8007\n",
            "TRAIN: step=3800, loss=172.3302\n",
            "TRAIN: step=4000, loss=43.6622\n",
            "TRAIN: step=4200, loss=73.0154\n",
            "TRAIN: step=4400, loss=293.4361\n",
            "TRAIN: step=4600, loss=121.3771\n",
            "TRAIN: step=4800, loss=79.1799\n",
            "TRAIN: step=5000, loss=342.9133\n",
            "TRAIN: step=5200, loss=135.9216\n",
            "TRAIN: step=5400, loss=120.6500\n",
            "TRAIN: step=5600, loss=243.5835\n",
            "TRAIN: step=5800, loss=12.0262\n",
            "TRAIN: step=6000, loss=173.1956\n",
            "TRAIN: step=6200, loss=262.2234\n",
            "TRAIN: step=6400, loss=97.2117\n",
            "TRAIN: step=6600, loss=192.9479\n",
            "TRAIN: step=6800, loss=187.3289\n",
            "TRAIN: step=7000, loss=112.7311\n",
            "TRAIN: step=7200, loss=26.1105\n",
            "TRAIN: step=7400, loss=113.1558\n",
            "TRAIN: step=7600, loss=271.8635\n",
            "TRAIN: step=7800, loss=217.8304\n",
            "TRAIN: step=8000, loss=51.8576\n",
            "TRAIN: step=8200, loss=168.7399\n",
            "TRAIN: step=8400, loss=72.7996\n",
            "TRAIN: step=8600, loss=365.7815\n",
            "TRAIN: step=8800, loss=87.9420\n",
            "TRAIN: step=9000, loss=91.4588\n",
            "TRAIN: step=9200, loss=102.4683\n",
            "TRAIN: step=9400, loss=85.9882\n",
            "TRAIN: step=9600, loss=79.7260\n",
            "TRAIN: step=9800, loss=100.3004\n",
            "TRAIN: step=10000, loss=154.4865\n",
            "TRAIN: step=10200, loss=270.5204\n",
            "TRAIN: step=10400, loss=49.9123\n",
            "TRAIN: step=10600, loss=28.7454\n",
            "TRAIN: step=10800, loss=319.1570\n",
            "TRAIN: step=11000, loss=71.7752\n",
            "TRAIN: step=11200, loss=135.8645\n",
            "TRAIN: step=11400, loss=51.0967\n",
            "TRAIN: step=11600, loss=64.4437\n",
            "TRAIN: step=11800, loss=65.5338\n",
            "TRAIN: step=12000, loss=167.6663\n",
            "TRAIN: step=12200, loss=149.3021\n",
            "TRAIN: step=12400, loss=59.7206\n",
            "TRAIN: step=12600, loss=66.0955\n",
            "TRAIN: step=12800, loss=62.3942\n",
            "TRAIN: step=13000, loss=71.2486\n",
            "TRAIN: step=13200, loss=68.5614\n",
            "TRAIN: step=13400, loss=123.2119\n",
            "TRAIN: step=13600, loss=67.1651\n",
            "TRAIN: step=13800, loss=137.0995\n",
            "TRAIN: step=14000, loss=661.2534\n",
            "TRAIN: step=14200, loss=255.8758\n",
            "TRAIN: step=14400, loss=44.7703\n",
            "TRAIN: step=14600, loss=51.2482\n",
            "TRAIN: step=14800, loss=62.5922\n",
            "TRAIN: step=15000, loss=123.8378\n",
            "TRAIN: step=15200, loss=11.2548\n",
            "TRAIN: step=15400, loss=381.6970\n",
            "TRAIN: step=15600, loss=599.4146\n",
            "TRAIN: step=15800, loss=294.2764\n",
            "TRAIN: step=16000, loss=65.0416\n",
            "TRAIN: step=16200, loss=134.2974\n",
            "TRAIN: step=16400, loss=102.0025\n",
            "TRAIN: step=16600, loss=193.1609\n",
            "TRAIN: step=16800, loss=183.2466\n",
            "TRAIN: step=17000, loss=108.0816\n",
            "TRAIN: step=17200, loss=71.1796\n",
            "TRAIN: step=17400, loss=163.1246\n",
            "TRAIN: step=17600, loss=12.1260\n",
            "TRAIN: step=17800, loss=75.5131\n",
            "TRAIN: step=18000, loss=90.5239\n",
            "TRAIN: step=18200, loss=72.8675\n",
            "TRAIN: step=18400, loss=38.3981\n",
            "TRAIN: step=18600, loss=26.9412\n",
            "TRAIN: step=18800, loss=118.5611\n",
            "TRAIN: step=19000, loss=18.0079\n",
            "TRAIN: step=19200, loss=219.1559\n",
            "TRAIN: step=19400, loss=202.5657\n",
            "TRAIN: step=19600, loss=69.2574\n",
            "TRAIN: step=19800, loss=2046.8741\n",
            "TRAIN: step=20000, loss=413.2579\n",
            "TRAIN: step=20200, loss=76.7165\n",
            "TRAIN: step=20400, loss=259.0219\n",
            "TRAIN: step=20600, loss=177.9585\n",
            "TRAIN: step=20800, loss=275.5030\n",
            "TRAIN: step=21000, loss=54.6167\n",
            "TRAIN: step=21200, loss=254.6640\n",
            "TRAIN: step=21400, loss=32.5527\n",
            "TRAIN: step=21600, loss=93.1732\n",
            "TRAIN: step=21800, loss=62.6213\n",
            "TRAIN: step=22000, loss=144.8335\n",
            "TRAIN: step=22200, loss=69.3339\n",
            "TRAIN: step=22400, loss=85.0839\n",
            "TRAIN: step=22600, loss=111.6931\n",
            "TRAIN: step=22800, loss=134.9486\n",
            "TRAIN: step=23000, loss=96.5481\n",
            "TRAIN: step=23200, loss=61.9875\n",
            "TRAIN: step=23400, loss=68.2702\n",
            "TRAIN: step=23600, loss=58.3282\n",
            "TRAIN: step=23800, loss=138.8008\n",
            "TRAIN: step=24000, loss=158.3723\n",
            "TRAIN: step=24200, loss=60.0311\n",
            "TRAIN: step=24400, loss=61.2898\n",
            "TRAIN: step=24600, loss=73.1794\n",
            "TRAIN: step=24800, loss=47.2503\n",
            "TRAIN: step=25000, loss=111.7689\n",
            "TRAIN: step=25200, loss=151.3027\n",
            "TRAIN: step=25400, loss=161.5903\n",
            "TRAIN: step=25600, loss=106.8483\n",
            "TRAIN: step=25800, loss=56.0339\n",
            "TRAIN: step=26000, loss=220.0811\n",
            "TRAIN: step=26200, loss=66.8430\n",
            "TRAIN: step=26400, loss=86.0568\n",
            "TRAIN: step=26600, loss=137.3413\n",
            "TRAIN: step=26800, loss=346.8173\n",
            "TRAIN: step=27000, loss=22.9477\n",
            "TRAIN: step=27200, loss=173.6847\n",
            "TRAIN: step=27400, loss=200.2851\n",
            "TRAIN: step=27600, loss=290.6597\n",
            "TRAIN: step=27800, loss=46.7561\n",
            "TRAIN: step=28000, loss=136.5575\n",
            "TRAIN: step=28200, loss=95.5963\n",
            "TRAIN: step=28400, loss=2372.5532\n",
            "TRAIN: step=28600, loss=65.8888\n",
            "TRAIN: step=28800, loss=167.2195\n",
            "TRAIN: step=29000, loss=99.3954\n",
            "TRAIN: step=29200, loss=86.2571\n",
            "TRAIN: step=29400, loss=128.3173\n",
            "TRAIN: step=29600, loss=85.0417\n",
            "TRAIN: step=29800, loss=308.9039\n",
            "TRAIN: step=30000, loss=82.4423\n",
            "TRAIN: step=30200, loss=35.7920\n",
            "TRAIN: step=30400, loss=112.3156\n",
            "TRAIN: step=30600, loss=331.4279\n",
            "TRAIN: step=30800, loss=49.4515\n",
            "TRAIN: step=31000, loss=154.2568\n",
            "TRAIN: step=31200, loss=22.4503\n",
            "TRAIN: step=31400, loss=24.6144\n",
            "TRAIN: step=31600, loss=92.0564\n",
            "TRAIN: step=31800, loss=61.8540\n",
            "TRAIN: step=32000, loss=153.6386\n",
            "TRAIN: step=32200, loss=121.9552\n",
            "TRAIN: step=32400, loss=53.0856\n",
            "TRAIN: step=32600, loss=79.0500\n",
            "TRAIN: step=32800, loss=415.0400\n",
            "TRAIN: step=33000, loss=196.5758\n",
            "TRAIN: step=33200, loss=12.2214\n",
            "TRAIN: step=33400, loss=43.4039\n",
            "TRAIN: step=33600, loss=113.6266\n",
            "TRAIN: step=33800, loss=299.4204\n",
            "TRAIN: step=34000, loss=112.5351\n",
            "TRAIN: step=34200, loss=157.3988\n",
            "TRAIN: step=34400, loss=277.7574\n",
            "TRAIN: step=34600, loss=154.8382\n",
            "TRAIN: step=34800, loss=56.4531\n",
            "TRAIN: step=35000, loss=83.4666\n",
            "TRAIN: step=35200, loss=363.6945\n",
            "TRAIN: step=35400, loss=27.2387\n",
            "TRAIN: step=35600, loss=71.1441\n",
            "TRAIN: step=35800, loss=219.1712\n",
            "TRAIN: step=36000, loss=134.2608\n",
            "TRAIN: step=36200, loss=97.0638\n",
            "TRAIN: step=36400, loss=126.6601\n",
            "TRAIN: step=36600, loss=50.3456\n",
            "TRAIN: step=36800, loss=138.4178\n",
            "TRAIN: step=37000, loss=187.8827\n",
            "TRAIN: step=37200, loss=161.8704\n",
            "TRAIN: step=37400, loss=136.7805\n",
            "TRAIN: step=37600, loss=371.9440\n",
            "TRAIN: step=37800, loss=100.5428\n",
            "TRAIN: step=38000, loss=209.0958\n",
            "TRAIN: step=38200, loss=89.0132\n",
            "TRAIN: step=38400, loss=137.1331\n",
            "TRAIN: step=38600, loss=79.2709\n",
            "TRAIN: step=38800, loss=86.5753\n",
            "TRAIN: step=39000, loss=24.5223\n",
            "TRAIN: step=39200, loss=101.4826\n",
            "TRAIN: step=39400, loss=233.8105\n",
            "TRAIN: step=39600, loss=95.2965\n",
            "TRAIN: step=39800, loss=221.8436\n",
            "TRAIN: step=40000, loss=141.5127\n",
            "TRAIN: step=40200, loss=122.7489\n",
            "TRAIN: step=40400, loss=61.0794\n",
            "TRAIN: step=40600, loss=115.3966\n",
            "TRAIN: step=40800, loss=58.4230\n",
            "TRAIN: step=41000, loss=172.6985\n",
            "TRAIN: step=41200, loss=111.5923\n",
            "TRAIN: step=41400, loss=166.0495\n",
            "TRAIN: step=41600, loss=289.7744\n",
            "TRAIN: step=41800, loss=348.7165\n",
            "TRAIN: step=42000, loss=149.3195\n",
            "TRAIN: step=42200, loss=114.5505\n",
            "TRAIN: step=42400, loss=27.5764\n",
            "TRAIN: step=42600, loss=34.0284\n",
            "TRAIN: step=42800, loss=20.1491\n",
            "TRAIN: step=43000, loss=192.1709\n",
            "TRAIN: step=43200, loss=139.3242\n",
            "TRAIN: step=43400, loss=191.9252\n",
            "TRAIN: step=43600, loss=30.3281\n",
            "TRAIN: step=43800, loss=157.5477\n",
            "TRAIN: step=44000, loss=127.0780\n",
            "TRAIN: step=44200, loss=75.8496\n",
            "TRAIN: step=44400, loss=24.8576\n",
            "TRAIN: step=44600, loss=257.8951\n",
            "TRAIN: step=44800, loss=136.9709\n",
            "TRAIN: step=45000, loss=232.2511\n",
            "TRAIN: step=45200, loss=42.2174\n",
            "TRAIN: step=45400, loss=100.2099\n",
            "TRAIN: step=45600, loss=59.7045\n",
            "TRAIN: step=45800, loss=62.6806\n",
            "TRAIN: step=46000, loss=102.0145\n",
            "TRAIN: step=46200, loss=23.5202\n",
            "TRAIN: step=46400, loss=293.8681\n",
            "TRAIN: step=46600, loss=63.5946\n",
            "TRAIN: step=46800, loss=20.8117\n",
            "TRAIN: step=47000, loss=317.3536\n",
            "TRAIN: step=47200, loss=193.8782\n",
            "TRAIN: step=47400, loss=218.9409\n",
            "TRAIN: step=47600, loss=194.2758\n",
            "TRAIN: step=47800, loss=115.3068\n",
            "TRAIN: step=48000, loss=19.8714\n",
            "TRAIN: step=48200, loss=95.6940\n",
            "TRAIN: step=48400, loss=61.0151\n",
            "TRAIN: step=48600, loss=72.7277\n",
            "TRAIN: step=48800, loss=216.2477\n",
            "TRAIN: step=49000, loss=70.7407\n",
            "TRAIN: step=49200, loss=44.3105\n",
            "TRAIN: step=49400, loss=96.4924\n",
            "TRAIN: step=49600, loss=82.3250\n",
            "TRAIN: step=49800, loss=125.2358\n",
            "TRAIN: step=50000, loss=269.0170\n",
            "TRAIN: step=50200, loss=59.2196\n",
            "TRAIN: step=50400, loss=96.5095\n",
            "TRAIN: step=50600, loss=29.8306\n",
            "TRAIN: step=50800, loss=68.7657\n",
            "TRAIN: step=51000, loss=106.5511\n",
            "TRAIN: step=51200, loss=55.2997\n",
            "TRAIN: step=51400, loss=101.5010\n",
            "TRAIN: step=51600, loss=50.2918\n",
            "TRAIN: step=51800, loss=77.7331\n",
            "TRAIN: step=52000, loss=352.6494\n",
            "TRAIN: step=52200, loss=413.2474\n",
            "TRAIN: step=52400, loss=177.5177\n",
            "TRAIN: step=52600, loss=161.6818\n",
            "TRAIN: step=52800, loss=153.5634\n",
            "TRAIN: step=53000, loss=125.0234\n",
            "TRAIN: step=53200, loss=117.3824\n",
            "TRAIN: step=53400, loss=90.5337\n",
            "TRAIN: step=53600, loss=219.9317\n",
            "TRAIN: step=53800, loss=106.4174\n",
            "TRAIN: step=54000, loss=29.1918\n",
            "TRAIN: step=54200, loss=140.8493\n",
            "TRAIN: step=54400, loss=118.8111\n",
            "TRAIN: step=54600, loss=86.5631\n",
            "TRAIN: step=54800, loss=435.1486\n",
            "TRAIN: step=55000, loss=139.3716\n",
            "TRAIN: step=55200, loss=109.0391\n",
            "TRAIN: step=55400, loss=202.7624\n",
            "TRAIN: step=55600, loss=670.3979\n",
            "TRAIN: step=55800, loss=311.0773\n",
            "TRAIN: step=56000, loss=110.1270\n",
            "TRAIN: step=56200, loss=258.6813\n",
            "TRAIN: step=56400, loss=81.6652\n",
            "TRAIN: step=56600, loss=39.6601\n",
            "TRAIN: step=56800, loss=148.2214\n",
            "TRAIN: step=57000, loss=555.9813\n",
            "TRAIN: step=57200, loss=109.3371\n",
            "TRAIN: step=57400, loss=46.9965\n",
            "TRAIN: step=57600, loss=41.0076\n",
            "TRAIN: step=57800, loss=189.1764\n",
            "TRAIN: step=58000, loss=39.1898\n",
            "TRAIN: step=58200, loss=172.5078\n",
            "TRAIN: step=58400, loss=36.8416\n",
            "TRAIN: step=58600, loss=145.6081\n",
            "TRAIN: step=58800, loss=113.4788\n",
            "TRAIN: step=59000, loss=235.2406\n",
            "TRAIN: step=59200, loss=231.1036\n",
            "TRAIN: step=59400, loss=99.6238\n",
            "TRAIN: step=59600, loss=120.7764\n",
            "TRAIN: step=59800, loss=200.7839\n",
            "TRAIN: step=60000, loss=35.0969\n",
            "TRAIN: step=60200, loss=57.6834\n",
            "TRAIN: step=60400, loss=28.3853\n",
            "TRAIN: step=60600, loss=82.2774\n",
            "TRAIN: step=60800, loss=29.3082\n",
            "TRAIN: step=61000, loss=41.6930\n",
            "TRAIN: step=61200, loss=185.7682\n",
            "TRAIN: step=61400, loss=28.2408\n",
            "TRAIN: step=61600, loss=204.9160\n",
            "TRAIN: step=61800, loss=75.0096\n",
            "TRAIN: step=62000, loss=30.8707\n",
            "TRAIN: step=62200, loss=290.3578\n",
            "TRAIN: step=62400, loss=342.4172\n",
            "TRAIN: step=62600, loss=79.3460\n",
            "TRAIN: step=62800, loss=80.1287\n",
            "TRAIN: step=63000, loss=110.5326\n",
            "TRAIN: step=63200, loss=168.3607\n",
            "TRAIN: step=63400, loss=71.4530\n",
            "TRAIN: step=63600, loss=203.9541\n",
            "TRAIN: step=63800, loss=51.5702\n",
            "TRAIN: step=64000, loss=85.8683\n",
            "TRAIN: step=64200, loss=147.7203\n",
            "TRAIN: step=64400, loss=37.8975\n",
            "TRAIN: step=64600, loss=219.3644\n",
            "TRAIN: step=64800, loss=211.1686\n",
            "TRAIN: step=65000, loss=313.5626\n",
            "TRAIN: step=65200, loss=153.5267\n",
            "TRAIN: step=65400, loss=61.8701\n",
            "TRAIN: step=65600, loss=144.4836\n",
            "TRAIN: step=65800, loss=24.8059\n",
            "TRAIN: step=66000, loss=82.8761\n",
            "TRAIN: step=66200, loss=271.2068\n",
            "TRAIN: step=66400, loss=38.7926\n",
            "TRAIN: step=66600, loss=185.9702\n",
            "TRAIN: step=66800, loss=203.0269\n",
            "TRAIN: step=67000, loss=167.4901\n",
            "TRAIN: step=67200, loss=200.0531\n",
            "TRAIN: step=67400, loss=121.3663\n",
            "TRAIN: step=67600, loss=35.3040\n",
            "TRAIN: step=67800, loss=227.4250\n",
            "TRAIN: step=68000, loss=143.8594\n",
            "TRAIN: step=68200, loss=247.7585\n",
            "TRAIN: step=68400, loss=99.4407\n",
            "TRAIN: step=68600, loss=95.9308\n",
            "TRAIN: step=68800, loss=115.2663\n",
            "TRAIN: step=69000, loss=162.8238\n",
            "TRAIN: step=69200, loss=105.9786\n",
            "TRAIN: step=69400, loss=75.4587\n",
            "TRAIN: step=69600, loss=238.2276\n",
            "TRAIN: step=69800, loss=21.6331\n",
            "TRAIN: step=70000, loss=55.1985\n",
            "TRAIN: step=70200, loss=539.2407\n",
            "TRAIN: step=70400, loss=55.7348\n",
            "TRAIN: step=70600, loss=99.3445\n",
            "TRAIN: step=70800, loss=116.6990\n",
            "TRAIN: step=71000, loss=42.9261\n",
            "TRAIN: step=71200, loss=159.3746\n",
            "TRAIN: step=71400, loss=79.1177\n",
            "TRAIN: step=71600, loss=39.3991\n",
            "TRAIN: step=71800, loss=63.8181\n",
            "src wrds tensor([ 0.0206, -0.0091, -0.0114,  0.0431, -0.0039,  0.0017,  0.0022, -0.0083,\n",
            "         0.0092, -0.0041,  0.0015, -0.0041, -0.0055, -0.0025, -0.0004,  0.0010,\n",
            "         0.0014,  0.0006,  0.0021, -0.0058], device='cuda:0') ['this', 'is', 'where', 'i', 'live', '.', 'i', 'live', 'in', 'kenya', ',', 'at', 'the', 'south', 'parts', 'of', 'the', 'nairobi', 'national', 'park', '.']\n",
            "src wrds tensor([-1.0677e-13, -1.1947e-13,  7.1141e-14, -9.0993e-14,  6.6960e-14,\n",
            "         7.4926e-14, -4.4617e-14,  5.7068e-14, -5.8174e-14, -6.5095e-14,\n",
            "         1.5035e-03, -4.0786e-03, -5.4566e-03, -2.4880e-03, -3.7248e-04,\n",
            "         1.0105e-03,  1.3519e-03,  6.1638e-04,  2.1309e-03, -5.7807e-03],\n",
            "       device='cuda:0') ['So', ',', 'this', 'is', 'a', 'story', 'about', 'how', 'we', 'know', 'what', 'we', 'know', '.']\n",
            "val epoch=0, BLEU=1.9500; best-ever=1.9500; report_val=1.9500; report_test=1.0300; report_epoch=0\n",
            "TEST epoch=0, BLEU=1.0300\n",
            "==================================================\n",
            "TRAIN: step=0, loss=72.1352\n",
            "TRAIN: step=200, loss=58.3140\n",
            "TRAIN: step=400, loss=150.6504\n",
            "TRAIN: step=600, loss=191.6426\n",
            "TRAIN: step=800, loss=131.9899\n",
            "TRAIN: step=1000, loss=46.9231\n",
            "TRAIN: step=1200, loss=15.2666\n",
            "TRAIN: step=1400, loss=5.1254\n",
            "TRAIN: step=1600, loss=32.1726\n",
            "TRAIN: step=1800, loss=30.8394\n",
            "TRAIN: step=2000, loss=584.5914\n",
            "TRAIN: step=2200, loss=110.0755\n",
            "TRAIN: step=2400, loss=23.5371\n",
            "TRAIN: step=2600, loss=87.3199\n",
            "TRAIN: step=2800, loss=168.1659\n",
            "TRAIN: step=3000, loss=51.7416\n",
            "TRAIN: step=3200, loss=81.2281\n",
            "TRAIN: step=3400, loss=88.9479\n",
            "TRAIN: step=3600, loss=171.8050\n",
            "TRAIN: step=3800, loss=213.7407\n",
            "TRAIN: step=4000, loss=142.9207\n",
            "TRAIN: step=4200, loss=113.7705\n",
            "TRAIN: step=4400, loss=86.6633\n",
            "TRAIN: step=4600, loss=488.5829\n",
            "TRAIN: step=4800, loss=23.0231\n",
            "TRAIN: step=5000, loss=605.2227\n",
            "TRAIN: step=5200, loss=62.2434\n",
            "TRAIN: step=5400, loss=215.3527\n",
            "TRAIN: step=5600, loss=115.2910\n",
            "TRAIN: step=5800, loss=37.1794\n",
            "TRAIN: step=6000, loss=152.7089\n",
            "TRAIN: step=6200, loss=149.7636\n",
            "TRAIN: step=6400, loss=59.5117\n",
            "TRAIN: step=6600, loss=173.9376\n",
            "TRAIN: step=6800, loss=112.2409\n",
            "TRAIN: step=7000, loss=53.8545\n",
            "TRAIN: step=7200, loss=48.2711\n",
            "TRAIN: step=7400, loss=35.0561\n",
            "TRAIN: step=7600, loss=143.1082\n",
            "TRAIN: step=7800, loss=175.1625\n",
            "TRAIN: step=8000, loss=82.6673\n",
            "TRAIN: step=8200, loss=42.2964\n",
            "TRAIN: step=8400, loss=49.9697\n",
            "TRAIN: step=8600, loss=127.2309\n",
            "TRAIN: step=8800, loss=43.2195\n",
            "TRAIN: step=9000, loss=24.2482\n",
            "TRAIN: step=9200, loss=252.1880\n",
            "TRAIN: step=9400, loss=133.5456\n",
            "TRAIN: step=9600, loss=98.6042\n",
            "TRAIN: step=9800, loss=119.3584\n",
            "TRAIN: step=10000, loss=115.8569\n",
            "TRAIN: step=10200, loss=79.4454\n",
            "TRAIN: step=10400, loss=67.3052\n",
            "TRAIN: step=10600, loss=72.5654\n",
            "TRAIN: step=10800, loss=381.4356\n",
            "TRAIN: step=11000, loss=155.7412\n",
            "TRAIN: step=11200, loss=82.4360\n",
            "TRAIN: step=11400, loss=148.3448\n",
            "TRAIN: step=11600, loss=190.7454\n",
            "TRAIN: step=11800, loss=34.6067\n",
            "TRAIN: step=12000, loss=171.0523\n",
            "TRAIN: step=12200, loss=199.6118\n",
            "TRAIN: step=12400, loss=64.1515\n",
            "TRAIN: step=12600, loss=30.7390\n",
            "TRAIN: step=12800, loss=160.3650\n",
            "TRAIN: step=13000, loss=20.9251\n",
            "TRAIN: step=13200, loss=87.8998\n",
            "TRAIN: step=13400, loss=108.0068\n",
            "TRAIN: step=13600, loss=57.3193\n",
            "TRAIN: step=13800, loss=0.5926\n",
            "TRAIN: step=14000, loss=277.1049\n",
            "TRAIN: step=14200, loss=105.7045\n",
            "TRAIN: step=14400, loss=43.0160\n",
            "TRAIN: step=14600, loss=36.8384\n",
            "TRAIN: step=14800, loss=28.8180\n",
            "TRAIN: step=15000, loss=300.5462\n",
            "TRAIN: step=15200, loss=197.2650\n",
            "TRAIN: step=15400, loss=72.2020\n",
            "TRAIN: step=15600, loss=46.7359\n",
            "TRAIN: step=15800, loss=53.5669\n",
            "TRAIN: step=16000, loss=118.1158\n",
            "TRAIN: step=16200, loss=157.3793\n",
            "TRAIN: step=16400, loss=52.0629\n",
            "TRAIN: step=16600, loss=90.9360\n",
            "TRAIN: step=16800, loss=73.8215\n",
            "TRAIN: step=17000, loss=138.2376\n",
            "TRAIN: step=17200, loss=97.9824\n",
            "TRAIN: step=17400, loss=414.2972\n",
            "TRAIN: step=17600, loss=166.2329\n",
            "TRAIN: step=17800, loss=229.1491\n",
            "TRAIN: step=18000, loss=11.8845\n",
            "TRAIN: step=18200, loss=201.8404\n",
            "TRAIN: step=18400, loss=83.3580\n",
            "TRAIN: step=18600, loss=44.8851\n",
            "TRAIN: step=18800, loss=17.1847\n",
            "TRAIN: step=19000, loss=127.0449\n",
            "TRAIN: step=19200, loss=671.7776\n",
            "TRAIN: step=19400, loss=148.0115\n",
            "TRAIN: step=19600, loss=97.2666\n",
            "TRAIN: step=19800, loss=150.3344\n",
            "TRAIN: step=20000, loss=112.0669\n",
            "TRAIN: step=20200, loss=317.2487\n",
            "TRAIN: step=20400, loss=52.2647\n",
            "TRAIN: step=20600, loss=96.2685\n",
            "TRAIN: step=20800, loss=34.8902\n",
            "TRAIN: step=21000, loss=60.9420\n",
            "TRAIN: step=21200, loss=136.2132\n",
            "TRAIN: step=21400, loss=69.5727\n",
            "TRAIN: step=21600, loss=220.6389\n",
            "TRAIN: step=21800, loss=111.9305\n",
            "TRAIN: step=22000, loss=62.6575\n",
            "TRAIN: step=22200, loss=32.6518\n",
            "TRAIN: step=22400, loss=50.6461\n",
            "TRAIN: step=22600, loss=381.7386\n",
            "TRAIN: step=22800, loss=265.4379\n",
            "TRAIN: step=23000, loss=204.9810\n",
            "TRAIN: step=23200, loss=95.6229\n",
            "TRAIN: step=23400, loss=25.1840\n",
            "TRAIN: step=23600, loss=181.8781\n",
            "TRAIN: step=23800, loss=99.4805\n",
            "TRAIN: step=24000, loss=147.6921\n",
            "TRAIN: step=24200, loss=12.4386\n",
            "TRAIN: step=24400, loss=211.1590\n",
            "TRAIN: step=24600, loss=28.0939\n",
            "TRAIN: step=24800, loss=93.6920\n",
            "TRAIN: step=25000, loss=72.1008\n",
            "TRAIN: step=25200, loss=147.1254\n",
            "TRAIN: step=25400, loss=117.6096\n",
            "TRAIN: step=25600, loss=73.2724\n",
            "TRAIN: step=25800, loss=109.4490\n",
            "TRAIN: step=26000, loss=206.6428\n",
            "TRAIN: step=26200, loss=85.5529\n",
            "TRAIN: step=26400, loss=44.6111\n",
            "TRAIN: step=26600, loss=32.7705\n",
            "TRAIN: step=26800, loss=37.5287\n",
            "TRAIN: step=27000, loss=55.7297\n",
            "TRAIN: step=27200, loss=48.8707\n",
            "TRAIN: step=27400, loss=54.9488\n",
            "TRAIN: step=27600, loss=48.0229\n",
            "TRAIN: step=27800, loss=61.3294\n",
            "TRAIN: step=28000, loss=58.1146\n",
            "TRAIN: step=28200, loss=139.3455\n",
            "TRAIN: step=28400, loss=233.4003\n",
            "TRAIN: step=28600, loss=330.3654\n",
            "TRAIN: step=28800, loss=145.5515\n",
            "TRAIN: step=29000, loss=71.5824\n",
            "TRAIN: step=29200, loss=179.4582\n",
            "TRAIN: step=29400, loss=113.9693\n",
            "TRAIN: step=29600, loss=197.7162\n",
            "TRAIN: step=29800, loss=6127.7529\n",
            "TRAIN: step=30000, loss=200.8601\n",
            "TRAIN: step=30200, loss=62.1436\n",
            "TRAIN: step=30400, loss=91.6516\n",
            "TRAIN: step=30600, loss=111.7252\n",
            "TRAIN: step=30800, loss=17.3452\n",
            "TRAIN: step=31000, loss=22.1518\n",
            "TRAIN: step=31200, loss=163.4700\n",
            "TRAIN: step=31400, loss=69.6881\n",
            "TRAIN: step=31600, loss=87.1589\n",
            "TRAIN: step=31800, loss=93.4449\n",
            "TRAIN: step=32000, loss=108.8287\n",
            "TRAIN: step=32200, loss=133.4222\n",
            "TRAIN: step=32400, loss=52.4195\n",
            "TRAIN: step=32600, loss=125.2777\n",
            "TRAIN: step=32800, loss=97.2551\n",
            "TRAIN: step=33000, loss=26.8112\n",
            "TRAIN: step=33200, loss=71.1980\n",
            "TRAIN: step=33400, loss=66.2920\n",
            "TRAIN: step=33600, loss=102.1818\n",
            "TRAIN: step=33800, loss=168.1648\n",
            "TRAIN: step=34000, loss=33.0757\n",
            "TRAIN: step=34200, loss=43.9986\n",
            "TRAIN: step=34400, loss=25.6065\n",
            "TRAIN: step=34600, loss=245.7080\n",
            "TRAIN: step=34800, loss=66.6815\n",
            "TRAIN: step=35000, loss=55.6226\n",
            "TRAIN: step=35200, loss=169.2691\n",
            "TRAIN: step=35400, loss=13.2931\n",
            "TRAIN: step=35600, loss=45.7194\n",
            "TRAIN: step=35800, loss=167.2435\n",
            "TRAIN: step=36000, loss=105.3502\n",
            "TRAIN: step=36200, loss=70.3510\n",
            "TRAIN: step=36400, loss=0.6230\n",
            "TRAIN: step=36600, loss=69.9895\n",
            "TRAIN: step=36800, loss=44.0577\n",
            "TRAIN: step=37000, loss=78.2855\n",
            "TRAIN: step=37200, loss=64.7476\n",
            "TRAIN: step=37400, loss=170.0107\n",
            "TRAIN: step=37600, loss=139.0036\n",
            "TRAIN: step=37800, loss=129.2711\n",
            "TRAIN: step=38000, loss=103.4309\n",
            "TRAIN: step=38200, loss=176.0302\n",
            "TRAIN: step=38400, loss=141.4600\n",
            "TRAIN: step=38600, loss=135.7761\n",
            "TRAIN: step=38800, loss=106.8018\n",
            "TRAIN: step=39000, loss=137.3658\n",
            "TRAIN: step=39200, loss=43.7199\n",
            "TRAIN: step=39400, loss=17.9151\n",
            "TRAIN: step=39600, loss=142.6107\n",
            "TRAIN: step=39800, loss=42.6986\n",
            "TRAIN: step=40000, loss=115.4214\n",
            "TRAIN: step=40200, loss=60.1198\n",
            "TRAIN: step=40400, loss=88.9691\n",
            "TRAIN: step=40600, loss=143.0129\n",
            "TRAIN: step=40800, loss=57.4547\n",
            "TRAIN: step=41000, loss=46.8353\n",
            "TRAIN: step=41200, loss=115.5785\n",
            "TRAIN: step=41400, loss=74.6974\n",
            "TRAIN: step=41600, loss=53.5148\n",
            "TRAIN: step=41800, loss=43.7474\n",
            "TRAIN: step=42000, loss=40.1229\n",
            "TRAIN: step=42200, loss=66.0878\n",
            "TRAIN: step=42400, loss=35.6847\n",
            "TRAIN: step=42600, loss=59.4623\n",
            "TRAIN: step=42800, loss=133.8263\n",
            "TRAIN: step=43000, loss=53.6730\n",
            "TRAIN: step=43200, loss=201.5786\n",
            "TRAIN: step=43400, loss=103.4939\n",
            "TRAIN: step=43600, loss=267.3988\n",
            "TRAIN: step=43800, loss=87.9347\n",
            "TRAIN: step=44000, loss=140.8900\n",
            "TRAIN: step=44200, loss=135.2737\n",
            "TRAIN: step=44400, loss=161.8876\n",
            "TRAIN: step=44600, loss=65.4203\n",
            "TRAIN: step=44800, loss=199.9779\n",
            "TRAIN: step=45000, loss=60.9252\n",
            "TRAIN: step=45200, loss=210.5767\n",
            "TRAIN: step=45400, loss=43.6370\n",
            "TRAIN: step=45600, loss=81.3071\n",
            "TRAIN: step=45800, loss=116.0918\n",
            "TRAIN: step=46000, loss=264.0802\n",
            "TRAIN: step=46200, loss=117.7472\n",
            "TRAIN: step=46400, loss=236.6462\n",
            "TRAIN: step=46600, loss=16.1623\n",
            "TRAIN: step=46800, loss=71.5507\n",
            "TRAIN: step=47000, loss=113.2743\n",
            "TRAIN: step=47200, loss=119.5341\n",
            "TRAIN: step=47400, loss=107.9039\n",
            "TRAIN: step=47600, loss=95.2884\n",
            "TRAIN: step=47800, loss=80.2214\n",
            "TRAIN: step=48000, loss=114.7276\n",
            "TRAIN: step=48200, loss=150.9854\n",
            "TRAIN: step=48400, loss=55.2298\n",
            "TRAIN: step=48600, loss=146.1776\n",
            "TRAIN: step=48800, loss=39.1233\n",
            "TRAIN: step=49000, loss=53.7328\n",
            "TRAIN: step=49200, loss=58.4875\n",
            "TRAIN: step=49400, loss=113.1295\n",
            "TRAIN: step=49600, loss=64.0210\n",
            "TRAIN: step=49800, loss=151.7260\n",
            "TRAIN: step=50000, loss=153.0428\n",
            "TRAIN: step=50200, loss=240.7736\n",
            "TRAIN: step=50400, loss=70.1285\n",
            "TRAIN: step=50600, loss=34.5066\n",
            "TRAIN: step=50800, loss=59.2963\n",
            "TRAIN: step=51000, loss=256.1596\n",
            "TRAIN: step=51200, loss=51.7720\n",
            "TRAIN: step=51400, loss=128.7550\n",
            "TRAIN: step=51600, loss=73.8667\n",
            "TRAIN: step=51800, loss=57.0878\n",
            "TRAIN: step=52000, loss=130.2286\n",
            "TRAIN: step=52200, loss=217.1220\n",
            "TRAIN: step=52400, loss=220.2719\n",
            "TRAIN: step=52600, loss=82.0067\n",
            "TRAIN: step=52800, loss=90.3941\n",
            "TRAIN: step=53000, loss=69.7387\n",
            "TRAIN: step=53200, loss=137.1245\n",
            "TRAIN: step=53400, loss=310.5001\n",
            "TRAIN: step=53600, loss=22.1015\n",
            "TRAIN: step=53800, loss=29.0104\n",
            "TRAIN: step=54000, loss=75.0088\n",
            "TRAIN: step=54200, loss=228.9099\n",
            "TRAIN: step=54400, loss=125.3161\n",
            "TRAIN: step=54600, loss=26.2214\n",
            "TRAIN: step=54800, loss=64.7650\n",
            "TRAIN: step=55000, loss=66.8921\n",
            "TRAIN: step=55200, loss=28.6355\n",
            "TRAIN: step=55400, loss=33.7665\n",
            "TRAIN: step=55600, loss=145.5429\n",
            "TRAIN: step=55800, loss=15.3351\n",
            "TRAIN: step=56000, loss=77.2113\n",
            "TRAIN: step=56200, loss=156.3595\n",
            "TRAIN: step=56400, loss=985.2692\n",
            "TRAIN: step=56600, loss=85.4406\n",
            "TRAIN: step=56800, loss=309.7705\n",
            "TRAIN: step=57000, loss=24.5747\n",
            "TRAIN: step=57200, loss=53.9585\n",
            "TRAIN: step=57400, loss=296.3307\n",
            "TRAIN: step=57600, loss=254.4456\n",
            "TRAIN: step=57800, loss=203.9402\n",
            "TRAIN: step=58000, loss=40.3944\n",
            "TRAIN: step=58200, loss=142.1213\n",
            "TRAIN: step=58400, loss=27.6271\n",
            "TRAIN: step=58600, loss=32.9358\n",
            "TRAIN: step=58800, loss=54.8073\n",
            "TRAIN: step=59000, loss=30.9242\n",
            "TRAIN: step=59200, loss=64.4801\n",
            "TRAIN: step=59400, loss=113.5168\n",
            "TRAIN: step=59600, loss=87.2821\n",
            "TRAIN: step=59800, loss=45.5454\n",
            "TRAIN: step=60000, loss=39.9677\n",
            "TRAIN: step=60200, loss=87.5245\n",
            "TRAIN: step=60400, loss=91.0613\n",
            "TRAIN: step=60600, loss=18.1266\n",
            "TRAIN: step=60800, loss=262.5565\n",
            "TRAIN: step=61000, loss=62.6598\n",
            "TRAIN: step=61200, loss=66.3977\n",
            "TRAIN: step=61400, loss=833.6008\n",
            "TRAIN: step=61600, loss=97.7862\n",
            "TRAIN: step=61800, loss=147.2245\n",
            "TRAIN: step=62000, loss=86.7363\n",
            "TRAIN: step=62200, loss=65.7278\n",
            "TRAIN: step=62400, loss=8.1433\n",
            "TRAIN: step=62600, loss=223.5264\n",
            "TRAIN: step=62800, loss=22.9125\n",
            "TRAIN: step=63000, loss=13.7492\n",
            "TRAIN: step=63200, loss=227.7155\n",
            "TRAIN: step=63400, loss=91.8873\n",
            "TRAIN: step=63600, loss=308.9702\n",
            "TRAIN: step=63800, loss=12.7172\n",
            "TRAIN: step=64000, loss=130.0810\n",
            "TRAIN: step=64200, loss=21.6705\n",
            "TRAIN: step=64400, loss=130.4980\n",
            "TRAIN: step=64600, loss=239.8610\n",
            "TRAIN: step=64800, loss=35.4873\n",
            "TRAIN: step=65000, loss=37.5632\n",
            "TRAIN: step=65200, loss=2299.9019\n",
            "TRAIN: step=65400, loss=212.1253\n",
            "TRAIN: step=65600, loss=88.0683\n",
            "TRAIN: step=65800, loss=26.8232\n",
            "TRAIN: step=66000, loss=89.9563\n",
            "TRAIN: step=66200, loss=27.0967\n",
            "TRAIN: step=66400, loss=83.5100\n",
            "TRAIN: step=66600, loss=2988.5303\n",
            "TRAIN: step=66800, loss=76.3450\n",
            "TRAIN: step=67000, loss=105.3118\n",
            "TRAIN: step=67200, loss=123.4801\n",
            "TRAIN: step=67400, loss=40.5352\n",
            "TRAIN: step=67600, loss=31.8280\n",
            "TRAIN: step=67800, loss=49.3198\n",
            "TRAIN: step=68000, loss=1111.6865\n",
            "TRAIN: step=68200, loss=30.4364\n",
            "TRAIN: step=68400, loss=19.0461\n",
            "TRAIN: step=68600, loss=89.5496\n",
            "TRAIN: step=68800, loss=106.7203\n",
            "TRAIN: step=69000, loss=86.0004\n",
            "TRAIN: step=69200, loss=146.5732\n",
            "TRAIN: step=69400, loss=23.8228\n",
            "TRAIN: step=69600, loss=162.4244\n",
            "TRAIN: step=69800, loss=40.4629\n",
            "TRAIN: step=70000, loss=61.9255\n",
            "TRAIN: step=70200, loss=3948.4592\n",
            "TRAIN: step=70400, loss=163.2500\n",
            "TRAIN: step=70600, loss=57.6893\n",
            "TRAIN: step=70800, loss=692.0474\n",
            "TRAIN: step=71000, loss=22.2843\n",
            "TRAIN: step=71200, loss=25.8946\n",
            "TRAIN: step=71400, loss=456.6902\n",
            "TRAIN: step=71600, loss=153.3874\n",
            "TRAIN: step=71800, loss=139.5199\n",
            "src wrds tensor([ 2.5161e-03, -3.2548e-04,  5.1036e-04,  3.0002e-03,  4.8208e-04,\n",
            "        -6.2362e-05,  9.7784e-05,  5.7484e-04,  9.2712e-04, -1.1993e-04,\n",
            "        -4.1129e-03, -7.1269e-03, -7.5391e-03, -2.8831e-03, -7.9635e-03,\n",
            "        -1.3799e-02, -1.4597e-02, -5.5823e-03, -1.2225e-02, -2.1184e-02],\n",
            "       device='cuda:0') ['this', 'is', 'where', 'i', 'live', '.', 'i', 'live', 'in', 'kenya', ',', 'at', 'the', 'south', 'parts', 'of', 'the', 'nairobi', 'national', 'park', '.']\n",
            "src wrds tensor([-1.0677e-13, -1.1947e-13,  7.1141e-14, -9.0993e-14,  6.6960e-14,\n",
            "         7.4926e-14, -4.4617e-14,  5.7068e-14, -5.8174e-14, -6.5095e-14,\n",
            "        -4.1129e-03, -7.1269e-03, -7.5391e-03, -2.8831e-03, -7.9635e-03,\n",
            "        -1.3799e-02, -1.4597e-02, -5.5823e-03, -1.2225e-02, -2.1184e-02],\n",
            "       device='cuda:0') ['So', ',', 'this', 'is', 'a', 'story', 'about', 'how', 'we', 'know', 'what', 'we', 'know', '.']\n",
            "val epoch=1, BLEU=7.7000; best-ever=7.7000; report_val=7.7000; report_test=5.0300; report_epoch=1\n",
            "TEST epoch=1, BLEU=5.0300\n",
            "==================================================\n",
            "TRAIN: step=0, loss=28.7429\n",
            "TRAIN: step=200, loss=93.7869\n",
            "TRAIN: step=400, loss=42.5948\n",
            "TRAIN: step=600, loss=107.4543\n",
            "TRAIN: step=800, loss=75.0635\n",
            "TRAIN: step=1000, loss=55.2576\n",
            "TRAIN: step=1200, loss=236.3682\n",
            "TRAIN: step=1400, loss=48.1145\n",
            "TRAIN: step=1600, loss=36.1859\n",
            "TRAIN: step=1800, loss=64.0415\n",
            "TRAIN: step=2000, loss=37.3132\n",
            "TRAIN: step=2200, loss=93.9566\n",
            "TRAIN: step=2400, loss=126.8490\n",
            "TRAIN: step=2600, loss=46.1350\n",
            "TRAIN: step=2800, loss=45.1014\n",
            "TRAIN: step=3000, loss=236.0187\n",
            "TRAIN: step=3200, loss=286.6573\n",
            "TRAIN: step=3400, loss=214.3905\n",
            "TRAIN: step=3600, loss=330.4207\n",
            "TRAIN: step=3800, loss=129.3073\n",
            "TRAIN: step=4000, loss=79.4863\n",
            "TRAIN: step=4200, loss=17.3720\n",
            "TRAIN: step=4400, loss=108.3698\n",
            "TRAIN: step=4600, loss=14.6644\n",
            "TRAIN: step=4800, loss=6.2383\n",
            "TRAIN: step=5000, loss=220.9761\n",
            "TRAIN: step=5200, loss=57.9667\n",
            "TRAIN: step=5400, loss=48.7672\n",
            "TRAIN: step=5600, loss=65.7725\n",
            "TRAIN: step=5800, loss=28.5213\n",
            "TRAIN: step=6000, loss=20.8007\n",
            "TRAIN: step=6200, loss=144.7145\n",
            "TRAIN: step=6400, loss=237.2173\n",
            "TRAIN: step=6600, loss=118.3625\n",
            "TRAIN: step=6800, loss=72.3405\n",
            "TRAIN: step=7000, loss=17.2563\n",
            "TRAIN: step=7200, loss=59.7213\n",
            "TRAIN: step=7400, loss=38.9986\n",
            "TRAIN: step=7600, loss=112.4318\n",
            "TRAIN: step=7800, loss=35.4986\n",
            "TRAIN: step=8000, loss=101.4738\n",
            "TRAIN: step=8200, loss=135.8832\n",
            "TRAIN: step=8400, loss=85.9655\n",
            "TRAIN: step=8600, loss=28.3496\n",
            "TRAIN: step=8800, loss=90.4269\n",
            "TRAIN: step=9000, loss=27.5570\n",
            "TRAIN: step=9200, loss=131.4734\n",
            "TRAIN: step=9400, loss=73.6608\n",
            "TRAIN: step=9600, loss=229.7182\n",
            "TRAIN: step=9800, loss=9.3455\n",
            "TRAIN: step=10000, loss=31.2299\n",
            "TRAIN: step=10200, loss=40.0959\n",
            "TRAIN: step=10400, loss=360.5676\n",
            "TRAIN: step=10600, loss=159.4999\n",
            "TRAIN: step=10800, loss=34.4588\n",
            "TRAIN: step=11000, loss=84.4001\n",
            "TRAIN: step=11200, loss=160.2410\n",
            "TRAIN: step=11400, loss=263.9139\n",
            "TRAIN: step=11600, loss=117.2578\n",
            "TRAIN: step=11800, loss=36.3816\n",
            "TRAIN: step=12000, loss=29.1754\n",
            "TRAIN: step=12200, loss=89.4664\n",
            "TRAIN: step=12400, loss=206.1435\n",
            "TRAIN: step=12600, loss=73.4215\n",
            "TRAIN: step=12800, loss=75.0571\n",
            "TRAIN: step=13000, loss=183.1413\n",
            "TRAIN: step=13200, loss=61.3234\n",
            "TRAIN: step=13400, loss=16.0306\n",
            "TRAIN: step=13600, loss=50.0434\n",
            "TRAIN: step=13800, loss=56.7488\n",
            "TRAIN: step=14000, loss=25.0708\n",
            "TRAIN: step=14200, loss=63.5903\n",
            "TRAIN: step=14400, loss=170.3830\n",
            "TRAIN: step=14600, loss=1869.9358\n",
            "TRAIN: step=14800, loss=56.3875\n",
            "TRAIN: step=15000, loss=72.6898\n",
            "TRAIN: step=15200, loss=188.5981\n",
            "TRAIN: step=15400, loss=822.5118\n",
            "TRAIN: step=15600, loss=145.7412\n",
            "TRAIN: step=15800, loss=60.5708\n",
            "TRAIN: step=16000, loss=199.5768\n",
            "TRAIN: step=16200, loss=203.8576\n",
            "TRAIN: step=16400, loss=108.2787\n",
            "TRAIN: step=16600, loss=54.2320\n",
            "TRAIN: step=16800, loss=196.2267\n",
            "TRAIN: step=17000, loss=39.6700\n",
            "TRAIN: step=17200, loss=87.7783\n",
            "TRAIN: step=17400, loss=39.1832\n",
            "TRAIN: step=17600, loss=55.1631\n",
            "TRAIN: step=17800, loss=909.3295\n",
            "TRAIN: step=18000, loss=160.9599\n",
            "TRAIN: step=18200, loss=166.6946\n",
            "TRAIN: step=18400, loss=69.4149\n",
            "TRAIN: step=18600, loss=14.1562\n",
            "TRAIN: step=18800, loss=119.0664\n",
            "TRAIN: step=19000, loss=104.2854\n",
            "TRAIN: step=19200, loss=51.1393\n",
            "TRAIN: step=19400, loss=8.7514\n",
            "TRAIN: step=19600, loss=51.7795\n",
            "TRAIN: step=19800, loss=135.3599\n",
            "TRAIN: step=20000, loss=146.2088\n",
            "TRAIN: step=20200, loss=140.0360\n",
            "TRAIN: step=20400, loss=208.9721\n",
            "TRAIN: step=20600, loss=341.5296\n",
            "TRAIN: step=20800, loss=40.6745\n",
            "TRAIN: step=21000, loss=12.0001\n",
            "TRAIN: step=21200, loss=143.7781\n",
            "TRAIN: step=21400, loss=18.3944\n",
            "TRAIN: step=21600, loss=64.7923\n",
            "TRAIN: step=21800, loss=123.2146\n",
            "TRAIN: step=22000, loss=23.6077\n",
            "TRAIN: step=22200, loss=78.6813\n",
            "TRAIN: step=22400, loss=64.6171\n",
            "TRAIN: step=22600, loss=39.9310\n",
            "TRAIN: step=22800, loss=110.2016\n",
            "TRAIN: step=23000, loss=107.6804\n",
            "TRAIN: step=23200, loss=96.1563\n",
            "TRAIN: step=23400, loss=72.1223\n",
            "TRAIN: step=23600, loss=19.5681\n",
            "TRAIN: step=23800, loss=129.6552\n",
            "TRAIN: step=24000, loss=118.5784\n",
            "TRAIN: step=24200, loss=33.0909\n",
            "TRAIN: step=24400, loss=274.8247\n",
            "TRAIN: step=24600, loss=260.4479\n",
            "TRAIN: step=24800, loss=88.2155\n",
            "TRAIN: step=25000, loss=23.0191\n",
            "TRAIN: step=25200, loss=63.2456\n",
            "TRAIN: step=25400, loss=34.1805\n",
            "TRAIN: step=25600, loss=29.1593\n",
            "TRAIN: step=25800, loss=442.2371\n",
            "TRAIN: step=26000, loss=24.0893\n",
            "TRAIN: step=26200, loss=38.3219\n",
            "TRAIN: step=26400, loss=nan\n",
            "TRAIN: step=26600, loss=nan\n",
            "TRAIN: step=26800, loss=nan\n",
            "TRAIN: step=27000, loss=nan\n",
            "TRAIN: step=27200, loss=nan\n",
            "TRAIN: step=27400, loss=nan\n",
            "TRAIN: step=27600, loss=nan\n",
            "TRAIN: step=27800, loss=nan\n",
            "TRAIN: step=28000, loss=nan\n",
            "TRAIN: step=28200, loss=nan\n",
            "TRAIN: step=28400, loss=nan\n",
            "TRAIN: step=28600, loss=nan\n",
            "TRAIN: step=28800, loss=nan\n",
            "TRAIN: step=29000, loss=nan\n",
            "TRAIN: step=29200, loss=nan\n",
            "TRAIN: step=29400, loss=nan\n",
            "TRAIN: step=29600, loss=nan\n",
            "TRAIN: step=29800, loss=nan\n",
            "TRAIN: step=30000, loss=nan\n",
            "TRAIN: step=30200, loss=nan\n",
            "TRAIN: step=30400, loss=nan\n",
            "TRAIN: step=30600, loss=nan\n",
            "TRAIN: step=30800, loss=nan\n",
            "TRAIN: step=31000, loss=nan\n",
            "TRAIN: step=31200, loss=nan\n",
            "TRAIN: step=31400, loss=nan\n",
            "TRAIN: step=31600, loss=nan\n",
            "TRAIN: step=31800, loss=nan\n",
            "TRAIN: step=32000, loss=nan\n",
            "TRAIN: step=32200, loss=nan\n",
            "TRAIN: step=32400, loss=nan\n",
            "TRAIN: step=32600, loss=nan\n",
            "TRAIN: step=32800, loss=nan\n",
            "TRAIN: step=33000, loss=nan\n",
            "TRAIN: step=33200, loss=nan\n",
            "TRAIN: step=33400, loss=nan\n",
            "TRAIN: step=33600, loss=nan\n",
            "TRAIN: step=33800, loss=nan\n",
            "TRAIN: step=34000, loss=nan\n",
            "TRAIN: step=34200, loss=nan\n",
            "TRAIN: step=34400, loss=nan\n",
            "TRAIN: step=34600, loss=nan\n",
            "TRAIN: step=34800, loss=nan\n",
            "TRAIN: step=35000, loss=nan\n",
            "TRAIN: step=35200, loss=nan\n",
            "TRAIN: step=35400, loss=nan\n",
            "TRAIN: step=35600, loss=nan\n",
            "TRAIN: step=35800, loss=nan\n",
            "TRAIN: step=36000, loss=nan\n",
            "TRAIN: step=36200, loss=nan\n",
            "TRAIN: step=36400, loss=nan\n",
            "TRAIN: step=36600, loss=nan\n",
            "TRAIN: step=36800, loss=nan\n",
            "TRAIN: step=37000, loss=nan\n",
            "TRAIN: step=37200, loss=nan\n",
            "TRAIN: step=37400, loss=nan\n",
            "TRAIN: step=37600, loss=nan\n",
            "TRAIN: step=37800, loss=nan\n",
            "TRAIN: step=38000, loss=nan\n",
            "TRAIN: step=38200, loss=nan\n",
            "TRAIN: step=38400, loss=nan\n",
            "TRAIN: step=38600, loss=nan\n",
            "TRAIN: step=38800, loss=nan\n",
            "TRAIN: step=39000, loss=nan\n",
            "TRAIN: step=39200, loss=nan\n",
            "TRAIN: step=39400, loss=nan\n",
            "TRAIN: step=39600, loss=nan\n",
            "TRAIN: step=39800, loss=nan\n",
            "TRAIN: step=40000, loss=nan\n",
            "TRAIN: step=40200, loss=nan\n",
            "TRAIN: step=40400, loss=nan\n",
            "TRAIN: step=40600, loss=nan\n",
            "TRAIN: step=40800, loss=nan\n",
            "TRAIN: step=41000, loss=nan\n",
            "TRAIN: step=41200, loss=nan\n",
            "TRAIN: step=41400, loss=nan\n",
            "TRAIN: step=41600, loss=nan\n",
            "TRAIN: step=41800, loss=nan\n",
            "TRAIN: step=42000, loss=nan\n",
            "TRAIN: step=42200, loss=nan\n",
            "TRAIN: step=42400, loss=nan\n",
            "TRAIN: step=42600, loss=nan\n",
            "TRAIN: step=42800, loss=nan\n",
            "TRAIN: step=43000, loss=nan\n",
            "TRAIN: step=43200, loss=nan\n",
            "TRAIN: step=43400, loss=nan\n",
            "TRAIN: step=43600, loss=nan\n",
            "TRAIN: step=43800, loss=nan\n",
            "TRAIN: step=44000, loss=nan\n",
            "TRAIN: step=44200, loss=nan\n",
            "TRAIN: step=44400, loss=nan\n",
            "TRAIN: step=44600, loss=nan\n",
            "TRAIN: step=44800, loss=nan\n",
            "TRAIN: step=45000, loss=nan\n",
            "TRAIN: step=45200, loss=nan\n",
            "TRAIN: step=45400, loss=nan\n",
            "TRAIN: step=45600, loss=nan\n",
            "TRAIN: step=45800, loss=nan\n",
            "TRAIN: step=46000, loss=nan\n",
            "TRAIN: step=46200, loss=nan\n",
            "TRAIN: step=46400, loss=nan\n",
            "TRAIN: step=46600, loss=nan\n",
            "TRAIN: step=46800, loss=nan\n",
            "TRAIN: step=47000, loss=nan\n",
            "TRAIN: step=47200, loss=nan\n",
            "TRAIN: step=47400, loss=nan\n",
            "TRAIN: step=47600, loss=nan\n",
            "TRAIN: step=47800, loss=nan\n",
            "TRAIN: step=48000, loss=nan\n",
            "TRAIN: step=48200, loss=nan\n",
            "TRAIN: step=48400, loss=nan\n",
            "TRAIN: step=48600, loss=nan\n",
            "TRAIN: step=48800, loss=nan\n",
            "TRAIN: step=49000, loss=nan\n",
            "TRAIN: step=49200, loss=nan\n",
            "TRAIN: step=49400, loss=nan\n",
            "TRAIN: step=49600, loss=nan\n",
            "TRAIN: step=49800, loss=nan\n",
            "TRAIN: step=50000, loss=nan\n",
            "TRAIN: step=50200, loss=nan\n",
            "TRAIN: step=50400, loss=nan\n",
            "TRAIN: step=50600, loss=nan\n",
            "TRAIN: step=50800, loss=nan\n",
            "TRAIN: step=51000, loss=nan\n",
            "TRAIN: step=51200, loss=nan\n",
            "TRAIN: step=51400, loss=nan\n",
            "TRAIN: step=51600, loss=nan\n",
            "TRAIN: step=51800, loss=nan\n",
            "TRAIN: step=52000, loss=nan\n",
            "TRAIN: step=52200, loss=nan\n",
            "TRAIN: step=52400, loss=nan\n",
            "TRAIN: step=52600, loss=nan\n",
            "TRAIN: step=52800, loss=nan\n",
            "TRAIN: step=53000, loss=nan\n",
            "TRAIN: step=53200, loss=nan\n",
            "TRAIN: step=53400, loss=nan\n",
            "TRAIN: step=53600, loss=nan\n",
            "TRAIN: step=53800, loss=nan\n",
            "TRAIN: step=54000, loss=nan\n",
            "TRAIN: step=54200, loss=nan\n",
            "TRAIN: step=54400, loss=nan\n",
            "TRAIN: step=54600, loss=nan\n",
            "TRAIN: step=54800, loss=nan\n",
            "TRAIN: step=55000, loss=nan\n",
            "TRAIN: step=55200, loss=nan\n",
            "TRAIN: step=55400, loss=nan\n",
            "TRAIN: step=55600, loss=nan\n",
            "TRAIN: step=55800, loss=nan\n",
            "TRAIN: step=56000, loss=nan\n",
            "TRAIN: step=56200, loss=nan\n",
            "TRAIN: step=56400, loss=nan\n",
            "TRAIN: step=56600, loss=nan\n",
            "TRAIN: step=56800, loss=nan\n",
            "TRAIN: step=57000, loss=nan\n",
            "TRAIN: step=57200, loss=nan\n",
            "TRAIN: step=57400, loss=nan\n",
            "TRAIN: step=57600, loss=nan\n",
            "TRAIN: step=57800, loss=nan\n",
            "TRAIN: step=58000, loss=nan\n",
            "TRAIN: step=58200, loss=nan\n",
            "TRAIN: step=58400, loss=nan\n",
            "TRAIN: step=58600, loss=nan\n",
            "TRAIN: step=58800, loss=nan\n",
            "TRAIN: step=59000, loss=nan\n",
            "TRAIN: step=59200, loss=nan\n",
            "TRAIN: step=59400, loss=nan\n",
            "TRAIN: step=59600, loss=nan\n",
            "TRAIN: step=59800, loss=nan\n",
            "TRAIN: step=60000, loss=nan\n",
            "TRAIN: step=60200, loss=nan\n",
            "TRAIN: step=60400, loss=nan\n",
            "TRAIN: step=60600, loss=nan\n",
            "TRAIN: step=60800, loss=nan\n",
            "TRAIN: step=61000, loss=nan\n",
            "TRAIN: step=61200, loss=nan\n",
            "TRAIN: step=61400, loss=nan\n",
            "TRAIN: step=61600, loss=nan\n",
            "TRAIN: step=61800, loss=nan\n",
            "TRAIN: step=62000, loss=nan\n",
            "TRAIN: step=62200, loss=nan\n",
            "TRAIN: step=62400, loss=nan\n",
            "TRAIN: step=62600, loss=nan\n",
            "TRAIN: step=62800, loss=nan\n",
            "TRAIN: step=63000, loss=nan\n",
            "TRAIN: step=63200, loss=nan\n",
            "TRAIN: step=63400, loss=nan\n",
            "TRAIN: step=63600, loss=nan\n",
            "TRAIN: step=63800, loss=nan\n",
            "TRAIN: step=64000, loss=nan\n",
            "TRAIN: step=64200, loss=nan\n",
            "TRAIN: step=64400, loss=nan\n",
            "TRAIN: step=64600, loss=nan\n",
            "TRAIN: step=64800, loss=nan\n",
            "TRAIN: step=65000, loss=nan\n",
            "TRAIN: step=65200, loss=nan\n",
            "TRAIN: step=65400, loss=nan\n",
            "TRAIN: step=65600, loss=nan\n",
            "TRAIN: step=65800, loss=nan\n",
            "TRAIN: step=66000, loss=nan\n",
            "TRAIN: step=66200, loss=nan\n",
            "TRAIN: step=66400, loss=nan\n",
            "TRAIN: step=66600, loss=nan\n",
            "TRAIN: step=66800, loss=nan\n",
            "TRAIN: step=67000, loss=nan\n",
            "TRAIN: step=67200, loss=nan\n",
            "TRAIN: step=67400, loss=nan\n",
            "TRAIN: step=67600, loss=nan\n",
            "TRAIN: step=67800, loss=nan\n",
            "TRAIN: step=68000, loss=nan\n",
            "TRAIN: step=68200, loss=nan\n",
            "TRAIN: step=68400, loss=nan\n",
            "TRAIN: step=68600, loss=nan\n",
            "TRAIN: step=68800, loss=nan\n",
            "TRAIN: step=69000, loss=nan\n",
            "TRAIN: step=69200, loss=nan\n",
            "TRAIN: step=69400, loss=nan\n",
            "TRAIN: step=69600, loss=nan\n",
            "TRAIN: step=69800, loss=nan\n",
            "TRAIN: step=70000, loss=nan\n",
            "TRAIN: step=70200, loss=nan\n",
            "TRAIN: step=70400, loss=nan\n",
            "TRAIN: step=70600, loss=nan\n",
            "TRAIN: step=70800, loss=nan\n",
            "TRAIN: step=71000, loss=nan\n",
            "TRAIN: step=71200, loss=nan\n",
            "TRAIN: step=71400, loss=nan\n",
            "TRAIN: step=71600, loss=nan\n",
            "TRAIN: step=71800, loss=nan\n",
            "src wrds tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
            "       device='cuda:0') ['this', 'is', 'where', 'i', 'live', '.', 'i', 'live', 'in', 'kenya', ',', 'at', 'the', 'south', 'parts', 'of', 'the', 'nairobi', 'national', 'park', '.']\n",
            "src wrds tensor([-1.0677e-13, -1.1947e-13,  7.1141e-14, -9.0993e-14,  6.6960e-14,\n",
            "         7.4926e-14, -4.4617e-14,  5.7068e-14, -5.8174e-14, -6.5095e-14,\n",
            "                nan,         nan,         nan,         nan,         nan,\n",
            "                nan,         nan,         nan,         nan,         nan],\n",
            "       device='cuda:0') ['So', ',', 'this', 'is', 'a', 'story', 'about', 'how', 'we', 'know', 'what', 'we', 'know', '.']\n",
            "val epoch=2, BLEU=0.0000; best-ever=7.7000; report_val=7.7000; report_test=5.0300; report_epoch=1\n",
            "TEST epoch=2, BLEU=0.0000\n",
            "==================================================\n",
            "TRAIN: step=0, loss=nan\n",
            "TRAIN: step=200, loss=nan\n",
            "TRAIN: step=400, loss=nan\n",
            "TRAIN: step=600, loss=nan\n",
            "TRAIN: step=800, loss=nan\n",
            "TRAIN: step=1000, loss=nan\n",
            "TRAIN: step=1200, loss=nan\n",
            "TRAIN: step=1400, loss=nan\n",
            "TRAIN: step=1600, loss=nan\n",
            "TRAIN: step=1800, loss=nan\n",
            "TRAIN: step=2000, loss=nan\n",
            "TRAIN: step=2200, loss=nan\n",
            "TRAIN: step=2400, loss=nan\n",
            "TRAIN: step=2600, loss=nan\n",
            "TRAIN: step=2800, loss=nan\n",
            "TRAIN: step=3000, loss=nan\n",
            "TRAIN: step=3200, loss=nan\n",
            "TRAIN: step=3400, loss=nan\n",
            "TRAIN: step=3600, loss=nan\n",
            "TRAIN: step=3800, loss=nan\n",
            "TRAIN: step=4000, loss=nan\n",
            "TRAIN: step=4200, loss=nan\n",
            "TRAIN: step=4400, loss=nan\n",
            "TRAIN: step=4600, loss=nan\n",
            "TRAIN: step=4800, loss=nan\n",
            "TRAIN: step=5000, loss=nan\n",
            "TRAIN: step=5200, loss=nan\n",
            "TRAIN: step=5400, loss=nan\n",
            "TRAIN: step=5600, loss=nan\n",
            "TRAIN: step=5800, loss=nan\n",
            "TRAIN: step=6000, loss=nan\n",
            "TRAIN: step=6200, loss=nan\n",
            "TRAIN: step=6400, loss=nan\n",
            "TRAIN: step=6600, loss=nan\n",
            "TRAIN: step=6800, loss=nan\n",
            "TRAIN: step=7000, loss=nan\n",
            "TRAIN: step=7200, loss=nan\n",
            "TRAIN: step=7400, loss=nan\n",
            "TRAIN: step=7600, loss=nan\n",
            "TRAIN: step=7800, loss=nan\n",
            "TRAIN: step=8000, loss=nan\n",
            "TRAIN: step=8200, loss=nan\n",
            "TRAIN: step=8400, loss=nan\n",
            "TRAIN: step=8600, loss=nan\n",
            "TRAIN: step=8800, loss=nan\n",
            "TRAIN: step=9000, loss=nan\n",
            "TRAIN: step=9200, loss=nan\n",
            "TRAIN: step=9400, loss=nan\n",
            "TRAIN: step=9600, loss=nan\n",
            "TRAIN: step=9800, loss=nan\n",
            "TRAIN: step=10000, loss=nan\n",
            "TRAIN: step=10200, loss=nan\n",
            "TRAIN: step=10400, loss=nan\n",
            "TRAIN: step=10600, loss=nan\n",
            "TRAIN: step=10800, loss=nan\n",
            "TRAIN: step=11000, loss=nan\n",
            "TRAIN: step=11200, loss=nan\n",
            "TRAIN: step=11400, loss=nan\n",
            "TRAIN: step=11600, loss=nan\n",
            "TRAIN: step=11800, loss=nan\n",
            "TRAIN: step=12000, loss=nan\n",
            "TRAIN: step=12200, loss=nan\n",
            "TRAIN: step=12400, loss=nan\n",
            "TRAIN: step=12600, loss=nan\n",
            "TRAIN: step=12800, loss=nan\n",
            "TRAIN: step=13000, loss=nan\n",
            "TRAIN: step=13200, loss=nan\n",
            "TRAIN: step=13400, loss=nan\n",
            "TRAIN: step=13600, loss=nan\n",
            "TRAIN: step=13800, loss=nan\n",
            "TRAIN: step=14000, loss=nan\n",
            "TRAIN: step=14200, loss=nan\n",
            "TRAIN: step=14400, loss=nan\n",
            "TRAIN: step=14600, loss=nan\n",
            "TRAIN: step=14800, loss=nan\n",
            "TRAIN: step=15000, loss=nan\n",
            "TRAIN: step=15200, loss=nan\n",
            "TRAIN: step=15400, loss=nan\n",
            "TRAIN: step=15600, loss=nan\n",
            "TRAIN: step=15800, loss=nan\n",
            "TRAIN: step=16000, loss=nan\n",
            "TRAIN: step=16200, loss=nan\n",
            "TRAIN: step=16400, loss=nan\n",
            "TRAIN: step=16600, loss=nan\n",
            "TRAIN: step=16800, loss=nan\n",
            "TRAIN: step=17000, loss=nan\n",
            "TRAIN: step=17200, loss=nan\n",
            "TRAIN: step=17400, loss=nan\n",
            "TRAIN: step=17600, loss=nan\n",
            "TRAIN: step=17800, loss=nan\n",
            "TRAIN: step=18000, loss=nan\n",
            "TRAIN: step=18200, loss=nan\n",
            "TRAIN: step=18400, loss=nan\n",
            "TRAIN: step=18600, loss=nan\n",
            "TRAIN: step=18800, loss=nan\n",
            "TRAIN: step=19000, loss=nan\n",
            "TRAIN: step=19200, loss=nan\n",
            "TRAIN: step=19400, loss=nan\n",
            "TRAIN: step=19600, loss=nan\n",
            "TRAIN: step=19800, loss=nan\n",
            "TRAIN: step=20000, loss=nan\n",
            "TRAIN: step=20200, loss=nan\n",
            "TRAIN: step=20400, loss=nan\n",
            "TRAIN: step=20600, loss=nan\n",
            "TRAIN: step=20800, loss=nan\n",
            "TRAIN: step=21000, loss=nan\n",
            "TRAIN: step=21200, loss=nan\n",
            "TRAIN: step=21400, loss=nan\n",
            "TRAIN: step=21600, loss=nan\n",
            "TRAIN: step=21800, loss=nan\n",
            "TRAIN: step=22000, loss=nan\n",
            "TRAIN: step=22200, loss=nan\n",
            "TRAIN: step=22400, loss=nan\n",
            "TRAIN: step=22600, loss=nan\n",
            "TRAIN: step=22800, loss=nan\n",
            "TRAIN: step=23000, loss=nan\n",
            "TRAIN: step=23200, loss=nan\n",
            "TRAIN: step=23400, loss=nan\n",
            "TRAIN: step=23600, loss=nan\n",
            "TRAIN: step=23800, loss=nan\n",
            "TRAIN: step=24000, loss=nan\n",
            "TRAIN: step=24200, loss=nan\n",
            "TRAIN: step=24400, loss=nan\n",
            "TRAIN: step=24600, loss=nan\n",
            "TRAIN: step=24800, loss=nan\n",
            "TRAIN: step=25000, loss=nan\n",
            "TRAIN: step=25200, loss=nan\n",
            "TRAIN: step=25400, loss=nan\n",
            "TRAIN: step=25600, loss=nan\n",
            "TRAIN: step=25800, loss=nan\n",
            "TRAIN: step=26000, loss=nan\n",
            "TRAIN: step=26200, loss=nan\n",
            "TRAIN: step=26400, loss=nan\n",
            "TRAIN: step=26600, loss=nan\n",
            "TRAIN: step=26800, loss=nan\n",
            "TRAIN: step=27000, loss=nan\n",
            "TRAIN: step=27200, loss=nan\n",
            "TRAIN: step=27400, loss=nan\n",
            "TRAIN: step=27600, loss=nan\n",
            "TRAIN: step=27800, loss=nan\n",
            "TRAIN: step=28000, loss=nan\n",
            "TRAIN: step=28200, loss=nan\n",
            "TRAIN: step=28400, loss=nan\n",
            "TRAIN: step=28600, loss=nan\n",
            "TRAIN: step=28800, loss=nan\n",
            "TRAIN: step=29000, loss=nan\n",
            "TRAIN: step=29200, loss=nan\n",
            "TRAIN: step=29400, loss=nan\n",
            "TRAIN: step=29600, loss=nan\n",
            "TRAIN: step=29800, loss=nan\n",
            "TRAIN: step=30000, loss=nan\n",
            "TRAIN: step=30200, loss=nan\n",
            "TRAIN: step=30400, loss=nan\n",
            "TRAIN: step=30600, loss=nan\n",
            "TRAIN: step=30800, loss=nan\n",
            "TRAIN: step=31000, loss=nan\n",
            "TRAIN: step=31200, loss=nan\n",
            "TRAIN: step=31400, loss=nan\n",
            "TRAIN: step=31600, loss=nan\n",
            "TRAIN: step=31800, loss=nan\n",
            "TRAIN: step=32000, loss=nan\n",
            "TRAIN: step=32200, loss=nan\n",
            "TRAIN: step=32400, loss=nan\n",
            "TRAIN: step=32600, loss=nan\n",
            "TRAIN: step=32800, loss=nan\n",
            "TRAIN: step=33000, loss=nan\n",
            "TRAIN: step=33200, loss=nan\n",
            "TRAIN: step=33400, loss=nan\n",
            "TRAIN: step=33600, loss=nan\n",
            "TRAIN: step=33800, loss=nan\n",
            "TRAIN: step=34000, loss=nan\n",
            "TRAIN: step=34200, loss=nan\n",
            "TRAIN: step=34400, loss=nan\n",
            "TRAIN: step=34600, loss=nan\n",
            "TRAIN: step=34800, loss=nan\n",
            "TRAIN: step=35000, loss=nan\n",
            "TRAIN: step=35200, loss=nan\n",
            "TRAIN: step=35400, loss=nan\n",
            "TRAIN: step=35600, loss=nan\n",
            "TRAIN: step=35800, loss=nan\n",
            "TRAIN: step=36000, loss=nan\n",
            "TRAIN: step=36200, loss=nan\n",
            "TRAIN: step=36400, loss=nan\n",
            "TRAIN: step=36600, loss=nan\n",
            "TRAIN: step=36800, loss=nan\n",
            "TRAIN: step=37000, loss=nan\n",
            "TRAIN: step=37200, loss=nan\n",
            "TRAIN: step=37400, loss=nan\n",
            "TRAIN: step=37600, loss=nan\n",
            "TRAIN: step=37800, loss=nan\n",
            "TRAIN: step=38000, loss=nan\n",
            "TRAIN: step=38200, loss=nan\n",
            "TRAIN: step=38400, loss=nan\n",
            "TRAIN: step=38600, loss=nan\n",
            "TRAIN: step=38800, loss=nan\n",
            "TRAIN: step=39000, loss=nan\n",
            "TRAIN: step=39200, loss=nan\n",
            "TRAIN: step=39400, loss=nan\n",
            "TRAIN: step=39600, loss=nan\n",
            "TRAIN: step=39800, loss=nan\n",
            "TRAIN: step=40000, loss=nan\n",
            "TRAIN: step=40200, loss=nan\n",
            "TRAIN: step=40400, loss=nan\n",
            "TRAIN: step=40600, loss=nan\n",
            "TRAIN: step=40800, loss=nan\n",
            "TRAIN: step=41000, loss=nan\n",
            "TRAIN: step=41200, loss=nan\n",
            "TRAIN: step=41400, loss=nan\n",
            "TRAIN: step=41600, loss=nan\n",
            "TRAIN: step=41800, loss=nan\n",
            "TRAIN: step=42000, loss=nan\n",
            "TRAIN: step=42200, loss=nan\n",
            "TRAIN: step=42400, loss=nan\n",
            "TRAIN: step=42600, loss=nan\n",
            "TRAIN: step=42800, loss=nan\n",
            "TRAIN: step=43000, loss=nan\n",
            "TRAIN: step=43200, loss=nan\n",
            "TRAIN: step=43400, loss=nan\n",
            "TRAIN: step=43600, loss=nan\n",
            "TRAIN: step=43800, loss=nan\n",
            "TRAIN: step=44000, loss=nan\n",
            "TRAIN: step=44200, loss=nan\n",
            "TRAIN: step=44400, loss=nan\n",
            "TRAIN: step=44600, loss=nan\n",
            "TRAIN: step=44800, loss=nan\n",
            "TRAIN: step=45000, loss=nan\n",
            "TRAIN: step=45200, loss=nan\n",
            "TRAIN: step=45400, loss=nan\n",
            "TRAIN: step=45600, loss=nan\n",
            "TRAIN: step=45800, loss=nan\n",
            "TRAIN: step=46000, loss=nan\n",
            "TRAIN: step=46200, loss=nan\n",
            "TRAIN: step=46400, loss=nan\n",
            "TRAIN: step=46600, loss=nan\n",
            "TRAIN: step=46800, loss=nan\n",
            "TRAIN: step=47000, loss=nan\n",
            "TRAIN: step=47200, loss=nan\n",
            "TRAIN: step=47400, loss=nan\n",
            "TRAIN: step=47600, loss=nan\n",
            "TRAIN: step=47800, loss=nan\n",
            "TRAIN: step=48000, loss=nan\n",
            "TRAIN: step=48200, loss=nan\n",
            "TRAIN: step=48400, loss=nan\n",
            "TRAIN: step=48600, loss=nan\n",
            "TRAIN: step=48800, loss=nan\n",
            "TRAIN: step=49000, loss=nan\n",
            "TRAIN: step=49200, loss=nan\n",
            "TRAIN: step=49400, loss=nan\n",
            "TRAIN: step=49600, loss=nan\n",
            "TRAIN: step=49800, loss=nan\n",
            "TRAIN: step=50000, loss=nan\n",
            "TRAIN: step=50200, loss=nan\n",
            "TRAIN: step=50400, loss=nan\n",
            "TRAIN: step=50600, loss=nan\n",
            "TRAIN: step=50800, loss=nan\n",
            "TRAIN: step=51000, loss=nan\n",
            "TRAIN: step=51200, loss=nan\n",
            "TRAIN: step=51400, loss=nan\n",
            "TRAIN: step=51600, loss=nan\n",
            "TRAIN: step=51800, loss=nan\n",
            "TRAIN: step=52000, loss=nan\n",
            "TRAIN: step=52200, loss=nan\n",
            "TRAIN: step=52400, loss=nan\n",
            "TRAIN: step=52600, loss=nan\n",
            "TRAIN: step=52800, loss=nan\n",
            "TRAIN: step=53000, loss=nan\n",
            "TRAIN: step=53200, loss=nan\n",
            "TRAIN: step=53400, loss=nan\n",
            "TRAIN: step=53600, loss=nan\n",
            "TRAIN: step=53800, loss=nan\n",
            "TRAIN: step=54000, loss=nan\n",
            "TRAIN: step=54200, loss=nan\n",
            "TRAIN: step=54400, loss=nan\n",
            "TRAIN: step=54600, loss=nan\n",
            "TRAIN: step=54800, loss=nan\n",
            "TRAIN: step=55000, loss=nan\n",
            "TRAIN: step=55200, loss=nan\n",
            "TRAIN: step=55400, loss=nan\n",
            "TRAIN: step=55600, loss=nan\n",
            "TRAIN: step=55800, loss=nan\n",
            "TRAIN: step=56000, loss=nan\n",
            "TRAIN: step=56200, loss=nan\n",
            "TRAIN: step=56400, loss=nan\n",
            "TRAIN: step=56600, loss=nan\n",
            "TRAIN: step=56800, loss=nan\n",
            "TRAIN: step=57000, loss=nan\n",
            "TRAIN: step=57200, loss=nan\n",
            "TRAIN: step=57400, loss=nan\n",
            "TRAIN: step=57600, loss=nan\n",
            "TRAIN: step=57800, loss=nan\n",
            "TRAIN: step=58000, loss=nan\n",
            "TRAIN: step=58200, loss=nan\n",
            "TRAIN: step=58400, loss=nan\n",
            "TRAIN: step=58600, loss=nan\n",
            "TRAIN: step=58800, loss=nan\n",
            "TRAIN: step=59000, loss=nan\n",
            "TRAIN: step=59200, loss=nan\n",
            "TRAIN: step=59400, loss=nan\n",
            "TRAIN: step=59600, loss=nan\n",
            "TRAIN: step=59800, loss=nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqOQ-qapZd-h"
      },
      "source": [
        "import torch, gc\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}